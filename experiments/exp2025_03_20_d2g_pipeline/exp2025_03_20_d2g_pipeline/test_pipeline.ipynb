{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph import metrics\n",
    "from dialogue2graph.pipelines.core.graph import Graph\n",
    "from dialogue2graph.pipelines.model_storage import ModelStorage\n",
    "from dialogue2graph.pipelines.helpers.parse_data import PipelineRawDataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.datasets.complex_dialogues import generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.save(\"model_storage.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 08:51:25,656 - dialogue2graph.pipelines.model_storage - INFO - Successfully loaded 0 models from model_storage.yml\n"
     ]
    }
   ],
   "source": [
    "ms.load(\"model_storage.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = generation.RecursiveDialogueSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transfer_2.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.invoke(Graph(data[\"true_graph\"]), ms.storage[\"grouping_llm\"].model, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2G Light pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.pipelines.d2g_light.pipeline import D2GLightPipeline\n",
    "\n",
    "pipeline = D2GLightPipeline(\n",
    "    name=\"d2g_light\",\n",
    "    model_storage=ms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"text\": \"Hey there! How can I help you today?\", \"participant\": \"assistant\"},\n",
    "    {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "    {\n",
    "        \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "        \"participant\": \"assistant\",\n",
    "    },\n",
    "    {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "    {\n",
    "        \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "        \"participant\": \"assistant\",\n",
    "    },\n",
    "    {\"text\": \"No, I'll manage on my own.\", \"participant\": \"user\"},\n",
    "    {\"text\": \"No worries! Feel free to reach out anytime.\", \"participant\": \"assistant\"},\n",
    "    {\"text\": \"Alright, thanks anyway.\", \"participant\": \"user\"},\n",
    "    {\"text\": \"You're welcome! Have a fantastic trip!\", \"participant\": \"assistant\"},\n",
    "]\n",
    "raw_data = PipelineRawDataType(dialogs=data)\n",
    "graph, report = pipeline.invoke(ms, \"d2g_light_sim_model:v1\", raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [\n",
    "        {\"text\": \"Hey there! How can I help you today?\", \"participant\": \"assistant\"},\n",
    "        {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Actually, never mind.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"Alright, let me know if you need help later. Have a great day!\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Okay, have a great day!\", \"participant\": \"user\"},\n",
    "        {\"text\": \"Glad to help! Safe travels.\", \"participant\": \"assistant\"},\n",
    "    ],\n",
    "    [\n",
    "        {\"text\": \"Hey there! How can I help you today?\", \"participant\": \"assistant\"},\n",
    "        {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"No, I'll manage on my own.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"No worries! Feel free to reach out anytime.\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Alright, thanks anyway.\", \"participant\": \"user\"},\n",
    "        {\"text\": \"You're welcome! Have a fantastic trip!\", \"participant\": \"assistant\"},\n",
    "    ],\n",
    "]\n",
    "raw_data = PipelineRawDataType(dialogs=data)\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"text\": \"Hey there! How can I help you today?\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"No, I'll manage on my own.\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"No worries! Feel free to reach out anytime.\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"Alright, thanks anyway.\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"You're welcome! Have a fantastic trip!\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "raw_data = PipelineRawDataType(dialogs=data)\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = Graph(data[\"true_graph\"])\n",
    "gr.graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transfer_2.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "raw_data = PipelineRawDataType(dialogs=data[\"dialogs\"])\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transfer_2.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "raw_data = PipelineRawDataType(dialogs=data[\"dialogs\"], true_graph=data[\"true_graph\"])\n",
    "graph, report = pipeline.invoke(ms, \"sim_model\", raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = PipelineRawDataType(dialogs=\"transfer_2.json\", true_graph=\"transfer_2.json\")\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_graph_1.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "Graph(data[\"true_graph\"]).visualise_short(\n",
    "    \"Fixing a calendar sync delay with time zones\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = PipelineRawDataType(dialogs=\"test_graph_1.json\")\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"Fixing a calendar sync delay with time zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = PipelineRawDataType(dialogs=data[\"dialogs\"], true_graph=data[\"true_graph\"])\n",
    "graph, report = pipeline.invoke(raw_data, enable_evals=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_metrics_data.json\", encoding=\"utf-8\") as f:\n",
    "    data_2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.metrics.llm_metrics import compare_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph(data_2[0][\"graph\"]).visualise_short(\"true_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': False, 'description': 'Numbers of nodes do not match: 8 != 7'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_graphs(Graph(data_2[1][\"graph\"]), graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualise_short(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_pipelines_data.json\", encoding=\"utf-8\") as f:\n",
    "    data_2 = json.load(f)\n",
    "raw_data = PipelineRawDataType(\n",
    "    dialogs=data_2[2][\"dialogues\"], true_graph=data_2[1][\"graph\"]\n",
    ")\n",
    "graph, report = pipeline.invoke(\n",
    "    ms, \"d2g_light_sim_model:v1\", raw_data, enable_evals=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"DeepPavlov/d2g_generated_augmented\", token=os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    ")\n",
    "data = dataset[\"train\"][0]\n",
    "data[\"dialogues\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "list_of_files = Path(\n",
    "    \"/data/home/peshkichev/projects/chatsky-llm-autoconfig/tests/metrics\"\n",
    ").glob(\"d2g_light*.json\")  # * means all if need specific format then *.csv\n",
    "latest_file = max(list_of_files, key=lambda x: x.stat().st_ctime)\n",
    "# latest_file = max(list_of_files, key=os.path.getctime)\n",
    "print(latest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = PipelineRawDataType(\n",
    "    dialogs=data[\"augmented_dialogues\"][0], true_graph=data[\"graph\"]\n",
    ")\n",
    "graph, report = pipeline.invoke(\n",
    "    ms, \"d2g_light_sim_model:v1\", raw_data, enable_evals=True\n",
    ")\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_graphs(Graph(data[\"graph\"]), graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"graph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"DeepPavlov/d2g_generated\", token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "data = dataset[\"train\"][0]\n",
    "data[\"dialogues\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[\"train\"][0]\n",
    "dialogs = data[\"dialogues\"][0][\"messages\"]\n",
    "graph = data[\"graph\"]\n",
    "raw_data = PipelineRawDataType(dialogs=dialogs, true_graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"graph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph(graph).visualise_short(\"true_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.properties[\"complex_graph_comparison\"][\"matched_triplets\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(report.properties[\"complex_graph_comparison\"][\"matched_triplets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2G LLM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.pipelines.d2g_llm.pipeline import D2GLLMPipeline\n",
    "\n",
    "pipeline = D2GLLMPipeline(\n",
    "    name=\"d2g_llm\",\n",
    "    model_storage=ms,\n",
    "    grouping_llm=\"grouping_llm\",\n",
    "    filling_llm=\"filling_llm\",\n",
    "    formatting_llm=\"formatting_llm\",\n",
    "    sim_model=\"sim_model\",\n",
    "    step2_evals=metrics.DGEvalBase,\n",
    "    end_evals=metrics.DGEvalBase,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = PipelineRawDataType(dialogs=\"transfer.json\")\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"text\": \"Hey there! How can I help you today?\", \"participant\": \"assistant\"},\n",
    "    {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "    {\n",
    "        \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "        \"participant\": \"assistant\",\n",
    "    },\n",
    "    {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "    {\n",
    "        \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "        \"participant\": \"assistant\",\n",
    "    },\n",
    "    {\"text\": \"No, I'll manage on my own.\", \"participant\": \"user\"},\n",
    "    {\"text\": \"No worries! Feel free to reach out anytime.\", \"participant\": \"assistant\"},\n",
    "    {\"text\": \"Alright, thanks anyway.\", \"participant\": \"user\"},\n",
    "    {\"text\": \"You're welcome! Have a fantastic trip!\", \"participant\": \"assistant\"},\n",
    "]\n",
    "raw_data = PipelineRawDataType(dialogs=data)\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [\n",
    "        {\"text\": \"Hey there! How can I help you today?\", \"participant\": \"assistant\"},\n",
    "        {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Actually, never mind.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"Alright, let me know if you need help later. Have a great day!\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Okay, have a great day!\", \"participant\": \"user\"},\n",
    "        {\"text\": \"Glad to help! Safe travels.\", \"participant\": \"assistant\"},\n",
    "    ],\n",
    "    [\n",
    "        {\"text\": \"Hey there! How can I help you today?\", \"participant\": \"assistant\"},\n",
    "        {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"No, I'll manage on my own.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"No worries! Feel free to reach out anytime.\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Alright, thanks anyway.\", \"participant\": \"user\"},\n",
    "        {\"text\": \"You're welcome! Have a fantastic trip!\", \"participant\": \"assistant\"},\n",
    "    ],\n",
    "]\n",
    "raw_data = PipelineRawDataType(dialogs=data)\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"text\": \"Hey there! How can I help you today?\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"No, I'll manage on my own.\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"No worries! Feel free to reach out anytime.\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"Alright, thanks anyway.\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"You're welcome! Have a fantastic trip!\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "raw_data = PipelineRawDataType(dialogs=data)\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transfer.json\") as f:\n",
    "    data = json.load(f)\n",
    "raw_data = PipelineRawDataType(dialogs=data)\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_graph_1.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "raw_data = PipelineRawDataType(dialogs=data[\"dialogs\"], true_graph=data[\"true_graph\"])\n",
    "graph, report = pipeline.invoke(raw_data, enable_evals=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2G LLM extender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.pipelines.d2g_extender.pipeline import D2GExtenderPipeline\n",
    "\n",
    "pipeline = D2GExtenderPipeline(\n",
    "    name=\"d2g_ext\",\n",
    "    model_storage=ms,\n",
    "    extending_llm=\"filling_llm\",\n",
    "    filling_llm=\"filling_llm\",\n",
    "    formatting_llm=\"formatting_llm\",\n",
    "    sim_model=\"sim_model\",\n",
    "    step1_evals=metrics.PreDGEvalBase,\n",
    "    extender_evals=metrics.PreDGEvalBase,\n",
    "    step2_evals=metrics.DGEvalBase,\n",
    "    end_evals=metrics.DGEvalBase,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"text\": \"Hey there! How can I help you today?\", \"participant\": \"assistant\"},\n",
    "    {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "    {\n",
    "        \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "        \"participant\": \"assistant\",\n",
    "    },\n",
    "    {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "    {\n",
    "        \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "        \"participant\": \"assistant\",\n",
    "    },\n",
    "    {\"text\": \"No, I'll manage on my own.\", \"participant\": \"user\"},\n",
    "    {\"text\": \"No worries! Feel free to reach out anytime.\", \"participant\": \"assistant\"},\n",
    "    {\"text\": \"Alright, thanks anyway.\", \"participant\": \"user\"},\n",
    "    {\"text\": \"You're welcome! Have a fantastic trip!\", \"participant\": \"assistant\"},\n",
    "]\n",
    "raw_data = PipelineRawDataType(dialogs=data)\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [\n",
    "        {\"text\": \"Hey there! How can I help you today?\", \"participant\": \"assistant\"},\n",
    "        {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Actually, never mind.\", \"participant\": \"user\"},\n",
    "        {\n",
    "            \"text\": \"Alright, let me know if you need help later. Have a great day!\",\n",
    "            \"participant\": \"assistant\",\n",
    "        },\n",
    "        {\"text\": \"Okay, have a great day!\", \"participant\": \"user\"},\n",
    "        {\"text\": \"Glad to help! Safe travels.\", \"participant\": \"assistant\"},\n",
    "    ]\n",
    "]\n",
    "raw_data = PipelineRawDataType(dialogs=data, supported_graph=graph.graph_dict)\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"text\": \"Hey there! How can I help you today?\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"I need to book a ride to the airport.\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"Sure! I can help with that. When is your flight, and where are you departing from?\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"Do you have any other options?\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"No, I'll manage on my own.\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"No worries! Feel free to reach out anytime.\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "            {\"text\": \"Alright, thanks anyway.\", \"participant\": \"user\"},\n",
    "            {\n",
    "                \"text\": \"You're welcome! Have a fantastic trip!\",\n",
    "                \"participant\": \"assistant\",\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "raw_data = PipelineRawDataType(dialogs=data)\n",
    "graph, report = pipeline.invoke(raw_data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph(data[\"true_graph\"]).graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_graph_1.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "Graph(data[\"true_graph\"]).visualise_short(\n",
    "    \"Fixing a calendar sync delay with time zones\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = PipelineRawDataType(dialogs=data[\"dialogs\"], true_graph=data[\"true_graph\"])\n",
    "graph, report = pipeline.invoke(raw_data, enable_evals=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualise_short(\"Fixing a calendar sync delay with time zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_metrics_data.json\", encoding=\"utf-8\") as f:\n",
    "    data_2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = PipelineRawDataType(\n",
    "    dialogs=data_2[2][\"dialogues\"], true_graph=data[\"true_graph\"]\n",
    ")\n",
    "graph, report = pipeline.invoke(raw_data, enable_evals=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = PipelineRawDataType(\n",
    "    dialogs=data_2[2][\"dialogues\"], true_graph=data_2[2][\"graph\"]\n",
    ")\n",
    "graph, report = pipeline.invoke(raw_data, enable_evals=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"DeepPavlov/d2g_generated_augmented\", token=os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"train\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

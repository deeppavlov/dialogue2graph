{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "255996ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-agentchat in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (0.5.7)\n",
      "Requirement already satisfied: autogen-core==0.5.7 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-agentchat) (0.5.7)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-agentchat) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-agentchat) (1.32.1)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-agentchat) (11.2.1)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-agentchat) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-agentchat) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-agentchat) (4.13.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.7->autogen-agentchat) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.7->autogen-agentchat) (8.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.7->autogen-agentchat) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.7->autogen-agentchat) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.7->autogen-agentchat) (0.4.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.5.7->autogen-agentchat) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.5.7->autogen-agentchat) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U \"autogen-agentchat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e24e3037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen-ext[openai] in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (0.5.7)\n",
      "Requirement already satisfied: autogen-core==0.5.7 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-ext[openai]) (0.5.7)\n",
      "Requirement already satisfied: aiofiles in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-ext[openai]) (24.1.0)\n",
      "Requirement already satisfied: openai>=1.66.5 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-ext[openai]) (1.75.0)\n",
      "Requirement already satisfied: tiktoken>=0.8.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-ext[openai]) (0.9.0)\n",
      "Requirement already satisfied: jsonref~=1.1.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-ext[openai]) (1.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-ext[openai]) (1.32.1)\n",
      "Requirement already satisfied: pillow>=11.0.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-ext[openai]) (11.2.1)\n",
      "Requirement already satisfied: protobuf~=5.29.3 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-ext[openai]) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-ext[openai]) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from autogen-core==0.5.7->autogen-ext[openai]) (4.13.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from openai>=1.66.5->autogen-ext[openai]) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from openai>=1.66.5->autogen-ext[openai]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from openai>=1.66.5->autogen-ext[openai]) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from openai>=1.66.5->autogen-ext[openai]) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from openai>=1.66.5->autogen-ext[openai]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from openai>=1.66.5->autogen-ext[openai]) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from tiktoken>=0.8.0->autogen-ext[openai]) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.66.5->autogen-ext[openai]) (3.10)\n",
      "Requirement already satisfied: certifi in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.66.5->autogen-ext[openai]) (0.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.7->autogen-ext[openai]) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from opentelemetry-api>=1.27.0->autogen-core==0.5.7->autogen-ext[openai]) (8.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.7->autogen-ext[openai]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.7->autogen-ext[openai]) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.0->autogen-core==0.5.7->autogen-ext[openai]) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.8.0->autogen-ext[openai]) (2.4.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->autogen-core==0.5.7->autogen-ext[openai]) (1.17.2)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.27.0->autogen-core==0.5.7->autogen-ext[openai]) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"autogen-ext[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f76550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca8b9c",
   "metadata": {},
   "source": [
    "# Single agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9c75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba231e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model client. You can use other model client that implements\n",
    "# the `ChatCompletionClient` interface.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bfd5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function tool that the agent can use.\n",
    "# For this example, we use a fake weather tool for demonstration purposes.\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7463f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an AssistantAgent with the model, tool, system message, and reflection enabled.\n",
    "# The system message instructs the agent via natural language.\n",
    "agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    reflect_on_tool_use=True,\n",
    "    model_client_stream=True,  # Enable streaming tokens from the model client.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "801f773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the agent and stream the messages to the console.\n",
    "async def main() -> None:\n",
    "    await Console(agent.run_stream(task=\"What is the weather in New York?\"))\n",
    "    # Close the connection to the model client.\n",
    "    await model_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e5ec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the weather in New York?\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='call_hy9ltCSLcqMJNADP4LGjWbVJ', arguments='{\"city\":\"New York\"}', name='get_weather')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 73 degrees and Sunny.', name='get_weather', call_id='call_hy9ltCSLcqMJNADP4LGjWbVJ', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "The current weather in New York is 73 degrees Fahrenheit and sunny.\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ffd93f",
   "metadata": {},
   "source": [
    "# Team (basic usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd1fe198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_agentchat.conditions import ExternalTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Create an OpenAI model client.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    api_key=os.environ['OPENAI_API_KEY']\n",
    ")\n",
    "\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Provide constructive feedback. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
    ")\n",
    "\n",
    "# Define a termination condition that stops the task if the critic approves.\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Create a team with the primary and critic agents.\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=text_termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02245dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=112), metadata={}, content=\"Leaves of amber gently fall,  \\nIn the whisper of the autumn call.  \\nA golden quilt on paths is spread,  \\nAs nature paints in hues of red.  \\n\\nCrisp air dances on the breeze,  \\nStirring thoughts with simple ease.  \\nPumpkin patches, fields of maize,  \\nHarvest moons in misty haze.  \\n\\nSweaters warm in the cool embrace,  \\nNostalgia found in each changed place.  \\nIn fall's brief song, the heart finds peace,  \\nIn the slowing rhythm, a sweet release.  \", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=157, completion_tokens=167), metadata={}, content='Your poem beautifully captures the essence of the fall season. The imagery of \"amber leaves\" and \"golden quilt\" vividly portrays the autumn landscape. The inclusion of sensory details like \"crisp air\" and \"sweaters warm\" enriches the reader\\'s experience. Additionally, the themes of nostalgia and peace provide a deeper emotional layer to the poem, resonating with the reflective nature of the season.\\n\\nTo enhance the poem further, consider adding a concluding line or stanza that ties together the imagery and emotions expressed throughout the poem. This could provide a satisfying closure to the reader\\'s journey through fall. Here\\'s a suggestion for the final touch:\\n\\n\"As autumn\\'s symphony comes to cease,  \\nWe gather memories that never cease.\"\\n\\nOverall, you\\'ve done an excellent job encapsulating the fall season in a poetic form. Well done!', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=315, completion_tokens=161), metadata={}, content=\"Thank you for the thoughtful critique and the wonderful suggestion! Here's the revised version with the added concluding lines:\\n\\nLeaves of amber gently fall,  \\nIn the whisper of the autumn call.  \\nA golden quilt on paths is spread,  \\nAs nature paints in hues of red.  \\n\\nCrisp air dances on the breeze,  \\nStirring thoughts with simple ease.  \\nPumpkin patches, fields of maize,  \\nHarvest moons in misty haze.  \\n\\nSweaters warm in the cool embrace,  \\nNostalgia found in each changed place.  \\nIn fall's brief song, the heart finds peace,  \\nIn the slowing rhythm, a sweet release.  \\n\\nAs autumn's symphony comes to cease,  \\nWe gather memories that never cease.  \\n\\nThank you again for your kind words and suggestion!\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=493, completion_tokens=3), metadata={}, content='APPROVE', type='TextMessage')] stop_reason=\"Text 'APPROVE' mentioned\"\n"
     ]
    }
   ],
   "source": [
    "# Use `asyncio.run(...)` when running in a script.\n",
    "result = await team.run(task=\"Write a short poem about the fall season.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc10027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextMessage(source='user', models_usage=None, metadata={}, content='Write a short poem about the fall season.', type='TextMessage'),\n",
       " TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=112), metadata={}, content=\"Leaves of amber gently fall,  \\nIn the whisper of the autumn call.  \\nA golden quilt on paths is spread,  \\nAs nature paints in hues of red.  \\n\\nCrisp air dances on the breeze,  \\nStirring thoughts with simple ease.  \\nPumpkin patches, fields of maize,  \\nHarvest moons in misty haze.  \\n\\nSweaters warm in the cool embrace,  \\nNostalgia found in each changed place.  \\nIn fall's brief song, the heart finds peace,  \\nIn the slowing rhythm, a sweet release.  \", type='TextMessage'),\n",
       " TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=157, completion_tokens=167), metadata={}, content='Your poem beautifully captures the essence of the fall season. The imagery of \"amber leaves\" and \"golden quilt\" vividly portrays the autumn landscape. The inclusion of sensory details like \"crisp air\" and \"sweaters warm\" enriches the reader\\'s experience. Additionally, the themes of nostalgia and peace provide a deeper emotional layer to the poem, resonating with the reflective nature of the season.\\n\\nTo enhance the poem further, consider adding a concluding line or stanza that ties together the imagery and emotions expressed throughout the poem. This could provide a satisfying closure to the reader\\'s journey through fall. Here\\'s a suggestion for the final touch:\\n\\n\"As autumn\\'s symphony comes to cease,  \\nWe gather memories that never cease.\"\\n\\nOverall, you\\'ve done an excellent job encapsulating the fall season in a poetic form. Well done!', type='TextMessage'),\n",
       " TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=315, completion_tokens=161), metadata={}, content=\"Thank you for the thoughtful critique and the wonderful suggestion! Here's the revised version with the added concluding lines:\\n\\nLeaves of amber gently fall,  \\nIn the whisper of the autumn call.  \\nA golden quilt on paths is spread,  \\nAs nature paints in hues of red.  \\n\\nCrisp air dances on the breeze,  \\nStirring thoughts with simple ease.  \\nPumpkin patches, fields of maize,  \\nHarvest moons in misty haze.  \\n\\nSweaters warm in the cool embrace,  \\nNostalgia found in each changed place.  \\nIn fall's brief song, the heart finds peace,  \\nIn the slowing rhythm, a sweet release.  \\n\\nAs autumn's symphony comes to cease,  \\nWe gather memories that never cease.  \\n\\nThank you again for your kind words and suggestion!\", type='TextMessage'),\n",
       " TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=493, completion_tokens=3), metadata={}, content='APPROVE', type='TextMessage')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7a82c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='user' models_usage=None metadata={} content='Write a short poem about the winter season.' type='TextMessage'\n",
      "source='primary' models_usage=RequestUsage(prompt_tokens=28, completion_tokens=131) metadata={} content=\"In a cloak of white, the world transforms,  \\nSilent whispers in the icy breeze,  \\nGlimmers of frost on the bare tree forms,  \\nA winter's canvas, sweeping with ease.  \\n\\nBlankets of snow drape the earth’s old face,  \\nCrystals glisten, lit by a pale sun,  \\nIn the quietude, a gentle grace,  \\nWhere time slows down, and the day's begun.  \\n\\nFootprints trace tales in the powdery white,  \\nUnderneath the stars’ soft, twinkling gleam,  \\nIn winter's embrace, a tranquil night,  \\nWhere nature dreams her frosted dream.  \" type='TextMessage'\n",
      "source='critic' models_usage=RequestUsage(prompt_tokens=177, completion_tokens=200) metadata={} content=\"Your poem beautifully captures the serene and magical essence of the winter season. The imagery is vivid, creating a picturesque setting that allows the reader to visualize and feel the quiet beauty of winter. The structure is consistent and the flow is smooth, which enhances the overall reading experience.\\n\\nHere are a few suggestions to further enhance the poem:\\n\\n1. **Variety in Descriptions**: While the descriptions are lovely, adding a bit more diversity can make each stanza stand out more. For example, incorporating more elements of winter activities or wildlife could add depth.\\n\\n2. **Sensory Details**: Incorporating other senses, such as the crunch of snow or the crispness of the cold air, can make the poem even more immersive.\\n\\n3. **Imagery Expansion**: Expanding on the imagery with metaphors or similes may help paint an even more vivid picture for the reader. \\n\\nConsider these points to refine the piece further. Otherwise, it's a beautifully written poem emblematic of the season!\" type='TextMessage'\n",
      "source='primary' models_usage=RequestUsage(prompt_tokens=368, completion_tokens=171) metadata={} content=\"Thank you for your thoughtful critique and suggestions. Here's a revised version of the poem, incorporating your feedback:\\n\\nIn a cloak of white, the world transforms,  \\nSilent whispers in the crisp, cold breeze,  \\nGlimmers of frost on the trees' bare forms,  \\nNature's delicate, hushed masterpiece.  \\n\\nBlankets of snow on earth's timeworn face,  \\nFootfalls crunch softly in powdery white,  \\nAs laughter echoes in frosty embrace,  \\nChildren building dreams in the pale moonlight.  \\n\\nBoughs heavy with snow, like silver lace,  \\nUnderneath the stars’ soft, twinkling gleam,  \\nA fox darts by, leaving its trace,  \\nNature in winter, a tranquil dream.  \\n\\nI hope these changes bring more depth and sensory richness to the poem while retaining its serene winter essence.\" type='TextMessage'\n",
      "source='critic' models_usage=RequestUsage(prompt_tokens=557, completion_tokens=146) metadata={} content='Your revisions have indeed added depth and sensory richness to the poem. The inclusion of additional elements like the \"footfalls crunch\" and \"laughter echoes\" enriches the sensory experience for the reader. You\\'ve skillfully incorporated nature and activity, such as \"children building dreams\" and \"a fox darts by,\" which offers a dynamic and lively aspect to the tranquil winter scene.\\n\\nThe addition of \"boughs heavy with snow, like silver lace\" provides a beautiful metaphor that enhances the imagery and adds elegance to the description. Overall, the updated poem feels more vivid and immersive, maintaining its serene essence while conveying a fuller range of winter\\'s beauty.\\n\\nYour revisions have effectively addressed the initial feedback. Well done!\\n\\nAPPROVE' type='TextMessage'\n",
      "Stop Reason: Text 'APPROVE' mentioned\n"
     ]
    }
   ],
   "source": [
    "# When running inside a script, use a async main function and call it from `asyncio.run(...)`.\n",
    "await team.reset()  # Reset the team for a new task.\n",
    "async for message in team.run_stream(task=\"Write a short poem about the winter season.\"):  # type: ignore\n",
    "    if isinstance(message, TaskResult):\n",
    "        print(\"Stop Reason:\", message.stop_reason)\n",
    "    else:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3452067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Text 'APPROVE' mentioned\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.stop_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "747c12e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a short poem about the summer season.\n",
      "---------- TextMessage (primary) ----------\n",
      "Golden rays kiss the earth with grace,  \n",
      "Under a vast, unclouded sky;  \n",
      "A gentle breeze in a sunlit embrace,  \n",
      "Whispers through fields where wildflowers lie.  \n",
      "\n",
      "Laughter echoes in the open air,  \n",
      "As waves dance upon the shore;  \n",
      "Days are long and free from care,  \n",
      "Where sun-drenched hearts begin to soar.  \n",
      "\n",
      "The world is alive with vibrant hue,  \n",
      "In the warmth of the summer's glow;  \n",
      "Nature's canvas, ever anew,  \n",
      "A fleeting beauty we come to know.  \n",
      "---------- TextMessage (critic) ----------\n",
      "Your poem beautifully captures the essence of summer with vivid imagery and evocative language. Here are a few suggestions that might enhance it even further:\n",
      "\n",
      "1. Consider adding a metaphor or simile to deepen the imagery. For example, comparing the sun to a specific golden object could enrich the description.\n",
      "   \n",
      "2. In the second stanza, consider expanding on how laughter and waves are connected to human experiences. This might create a stronger emotional connection for the reader.\n",
      "\n",
      "3. The rhythm and flow of the poem can be enhanced by maintaining a consistent syllable count or beat throughout each line. This could improve the poem’s musicality.\n",
      "\n",
      "4. Try to incorporate sensory detail for a fuller experience. Mentioning scents, sounds, or textures could draw the reader deeper into the world you're creating.\n",
      "\n",
      "Overall, you've created a lovely depiction of summer's brightness and joy. With a few tweaks, it could be even more immersive and evocative. Keep up the great work!\n",
      "---------- TextMessage (primary) ----------\n",
      "Thank you for your thoughtful feedback! I've revised the poem with your suggestions in mind:\n",
      "\n",
      "---\n",
      "\n",
      "Golden rays like molten gold spill,  \n",
      "Under a vast, unclouded sky;  \n",
      "A gentle breeze with a tender quill,  \n",
      "Writes whispers where wildflowers lie.  \n",
      "\n",
      "Laughter rises with the ocean's roar,  \n",
      "As waves hug the sandy shore;  \n",
      "People bask in memories while,  \n",
      "The warm sun wraps them more and more.  \n",
      "\n",
      "The world hums in colors wildly true,  \n",
      "In summer's bright, embracing glow;  \n",
      "Perfumes of blooms in the air accrue,  \n",
      "A tapestry of life we come to know.  \n",
      "\n",
      "---\n",
      "\n",
      "I incorporated a metaphor in the first line, strengthened the emotional connection with human experiences in the second stanza, aimed for a consistent rhythm, and added sensory details throughout. I hope these enhancements bring the poem to life!\n",
      "---------- TextMessage (critic) ----------\n",
      "Your revisions have wonderfully enhanced the poem! The metaphor in the first line sets a vivid and compelling tone, effectively drawing the reader into the scene. The incorporation of sensory details like \"perfumes of blooms\" and the emotional connection in the second stanza significantly enrich the imagery and emotional resonance. The poem now flows with a consistent rhythm, making it pleasant to read aloud. Your efforts have successfully brought the poem to life, capturing the vibrant and dynamic essence of the summer season. Well done! \n",
      "\n",
      "APPROVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Write a short poem about the summer season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=113), metadata={}, content=\"Golden rays kiss the earth with grace,  \\nUnder a vast, unclouded sky;  \\nA gentle breeze in a sunlit embrace,  \\nWhispers through fields where wildflowers lie.  \\n\\nLaughter echoes in the open air,  \\nAs waves dance upon the shore;  \\nDays are long and free from care,  \\nWhere sun-drenched hearts begin to soar.  \\n\\nThe world is alive with vibrant hue,  \\nIn the warmth of the summer's glow;  \\nNature's canvas, ever anew,  \\nA fleeting beauty we come to know.  \", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=158, completion_tokens=190), metadata={}, content=\"Your poem beautifully captures the essence of summer with vivid imagery and evocative language. Here are a few suggestions that might enhance it even further:\\n\\n1. Consider adding a metaphor or simile to deepen the imagery. For example, comparing the sun to a specific golden object could enrich the description.\\n   \\n2. In the second stanza, consider expanding on how laughter and waves are connected to human experiences. This might create a stronger emotional connection for the reader.\\n\\n3. The rhythm and flow of the poem can be enhanced by maintaining a consistent syllable count or beat throughout each line. This could improve the poem’s musicality.\\n\\n4. Try to incorporate sensory detail for a fuller experience. Mentioning scents, sounds, or textures could draw the reader deeper into the world you're creating.\\n\\nOverall, you've created a lovely depiction of summer's brightness and joy. With a few tweaks, it could be even more immersive and evocative. Keep up the great work!\", type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=340, completion_tokens=173), metadata={}, content=\"Thank you for your thoughtful feedback! I've revised the poem with your suggestions in mind:\\n\\n---\\n\\nGolden rays like molten gold spill,  \\nUnder a vast, unclouded sky;  \\nA gentle breeze with a tender quill,  \\nWrites whispers where wildflowers lie.  \\n\\nLaughter rises with the ocean's roar,  \\nAs waves hug the sandy shore;  \\nPeople bask in memories while,  \\nThe warm sun wraps them more and more.  \\n\\nThe world hums in colors wildly true,  \\nIn summer's bright, embracing glow;  \\nPerfumes of blooms in the air accrue,  \\nA tapestry of life we come to know.  \\n\\n---\\n\\nI incorporated a metaphor in the first line, strengthened the emotional connection with human experiences in the second stanza, aimed for a consistent rhythm, and added sensory details throughout. I hope these enhancements bring the poem to life!\", type='TextMessage'), TextMessage(source='critic', models_usage=RequestUsage(prompt_tokens=530, completion_tokens=101), metadata={}, content='Your revisions have wonderfully enhanced the poem! The metaphor in the first line sets a vivid and compelling tone, effectively drawing the reader into the scene. The incorporation of sensory details like \"perfumes of blooms\" and the emotional connection in the second stanza significantly enrich the imagery and emotional resonance. The poem now flows with a consistent rhythm, making it pleasant to read aloud. Your efforts have successfully brought the poem to life, capturing the vibrant and dynamic essence of the summer season. Well done! \\n\\nAPPROVE', type='TextMessage')], stop_reason=\"Text 'APPROVE' mentioned\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await team.reset()  # Reset the team for a new task.\n",
    "await Console(team.run_stream(task=\"Write a short poem about the summer season.\"))  # Stream the messages to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae5568",
   "metadata": {},
   "source": [
    "There is no summary as opposed to an example in the tutorial.\n",
    "```\n",
    "---------- Summary ----------\n",
    "Number of messages: 5\n",
    "Finish reason: Text 'APPROVE' mentioned\n",
    "Total prompt tokens: 972\n",
    "Total completion tokens: 455\n",
    "Duration: 11.78 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48125351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a short poem about the spring season.\n",
      "---------- TextMessage (primary) ----------\n",
      "Blossoms whisper in the warming breeze,  \n",
      "As tender buds begin to wake;  \n",
      "The world awash with vibrant ease,  \n",
      "In hues that only spring can make.  \n",
      "\n",
      "The symphony of life takes flight,  \n",
      "With birds that sing in joyful cheer;  \n",
      "Days stretch longer, bathed in light,  \n",
      "As hope renews with each dawn near.  \n",
      "\n",
      "Gentle rains kiss the earth anew,  \n",
      "Awakening dreams in hidden seeds;  \n",
      "A tapestry of life and hue,  \n",
      "In spring's embrace, the heart concedes.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Write a short poem about the spring season.', type='TextMessage'), TextMessage(source='primary', models_usage=RequestUsage(prompt_tokens=530, completion_tokens=111), metadata={}, content=\"Blossoms whisper in the warming breeze,  \\nAs tender buds begin to wake;  \\nThe world awash with vibrant ease,  \\nIn hues that only spring can make.  \\n\\nThe symphony of life takes flight,  \\nWith birds that sing in joyful cheer;  \\nDays stretch longer, bathed in light,  \\nAs hope renews with each dawn near.  \\n\\nGentle rains kiss the earth anew,  \\nAwakening dreams in hidden seeds;  \\nA tapestry of life and hue,  \\nIn spring's embrace, the heart concedes.  \", type='TextMessage')], stop_reason='External termination requested')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new team with an external termination condition.\n",
    "external_termination = ExternalTermination()\n",
    "team = RoundRobinGroupChat(\n",
    "    [primary_agent, critic_agent],\n",
    "    termination_condition=external_termination | text_termination,  # Use the bitwise OR operator to combine conditions.\n",
    ")\n",
    "\n",
    "# Run the team in a background task.\n",
    "run = asyncio.create_task(Console(team.run_stream(task=\"Write a short poem about the spring season.\")))\n",
    "\n",
    "# Wait for some time.\n",
    "await asyncio.sleep(0.1)\n",
    "\n",
    "# Stop the team.\n",
    "external_termination.set()\n",
    "\n",
    "# Wait for the team to finish.\n",
    "await run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1af1bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task was cancelled.\n"
     ]
    }
   ],
   "source": [
    "# Create a cancellation token.\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Use another coroutine to run the team.\n",
    "run = asyncio.create_task(\n",
    "    team.run(\n",
    "        task=\"Translate the poem to Spanish.\",\n",
    "        cancellation_token=cancellation_token,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cancel the run.\n",
    "cancellation_token.cancel()\n",
    "\n",
    "try:\n",
    "    result = await run  # This will raise a CancelledError.\n",
    "except asyncio.CancelledError:\n",
    "    print(\"Task was cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e0bda9",
   "metadata": {},
   "source": [
    "## Single agent team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73c1fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextMessage source='user' models_usage=None metadata={} content='Increment the number 5 to 10.' type='TextMessage'\n",
      "ToolCallRequestEvent source='looped_assistant' models_usage=RequestUsage(prompt_tokens=75, completion_tokens=15) metadata={} content=[FunctionCall(id='call_Xqx398CD0LUl6OAxtUYrdu8h', arguments='{\"number\":5}', name='increment_number')] type='ToolCallRequestEvent'\n",
      "ToolCallExecutionEvent source='looped_assistant' models_usage=None metadata={} content=[FunctionExecutionResult(content='6', name='increment_number', call_id='call_Xqx398CD0LUl6OAxtUYrdu8h', is_error=False)] type='ToolCallExecutionEvent'\n",
      "ToolCallSummaryMessage source='looped_assistant' models_usage=None metadata={} content='6' type='ToolCallSummaryMessage'\n",
      "ToolCallRequestEvent source='looped_assistant' models_usage=RequestUsage(prompt_tokens=98, completion_tokens=15) metadata={} content=[FunctionCall(id='call_Zgily0MIksJxoOMghtBic8qg', arguments='{\"number\":6}', name='increment_number')] type='ToolCallRequestEvent'\n",
      "ToolCallExecutionEvent source='looped_assistant' models_usage=None metadata={} content=[FunctionExecutionResult(content='7', name='increment_number', call_id='call_Zgily0MIksJxoOMghtBic8qg', is_error=False)] type='ToolCallExecutionEvent'\n",
      "ToolCallSummaryMessage source='looped_assistant' models_usage=None metadata={} content='7' type='ToolCallSummaryMessage'\n",
      "ToolCallRequestEvent source='looped_assistant' models_usage=RequestUsage(prompt_tokens=121, completion_tokens=14) metadata={} content=[FunctionCall(id='call_OYmfHXN2SHOpmAk57eRD6I2J', arguments='{\"number\":7}', name='increment_number')] type='ToolCallRequestEvent'\n",
      "ToolCallExecutionEvent source='looped_assistant' models_usage=None metadata={} content=[FunctionExecutionResult(content='8', name='increment_number', call_id='call_OYmfHXN2SHOpmAk57eRD6I2J', is_error=False)] type='ToolCallExecutionEvent'\n",
      "ToolCallSummaryMessage source='looped_assistant' models_usage=None metadata={} content='8' type='ToolCallSummaryMessage'\n",
      "ToolCallRequestEvent source='looped_assistant' models_usage=RequestUsage(prompt_tokens=144, completion_tokens=15) metadata={} content=[FunctionCall(id='call_z6B1xM6Br7YSZpEUEN31pKfz', arguments='{\"number\":8}', name='increment_number')] type='ToolCallRequestEvent'\n",
      "ToolCallExecutionEvent source='looped_assistant' models_usage=None metadata={} content=[FunctionExecutionResult(content='9', name='increment_number', call_id='call_z6B1xM6Br7YSZpEUEN31pKfz', is_error=False)] type='ToolCallExecutionEvent'\n",
      "ToolCallSummaryMessage source='looped_assistant' models_usage=None metadata={} content='9' type='ToolCallSummaryMessage'\n",
      "ToolCallRequestEvent source='looped_assistant' models_usage=RequestUsage(prompt_tokens=167, completion_tokens=15) metadata={} content=[FunctionCall(id='call_TaJwx22A9xSwU1DADuLEuTqu', arguments='{\"number\":9}', name='increment_number')] type='ToolCallRequestEvent'\n",
      "ToolCallExecutionEvent source='looped_assistant' models_usage=None metadata={} content=[FunctionExecutionResult(content='10', name='increment_number', call_id='call_TaJwx22A9xSwU1DADuLEuTqu', is_error=False)] type='ToolCallExecutionEvent'\n",
      "ToolCallSummaryMessage source='looped_assistant' models_usage=None metadata={} content='10' type='ToolCallSummaryMessage'\n",
      "TextMessage source='looped_assistant' models_usage=RequestUsage(prompt_tokens=190, completion_tokens=14) metadata={} content='The number has been incremented from 5 to 10.' type='TextMessage'\n",
      "TaskResult messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Increment the number 5 to 10.', type='TextMessage'), ToolCallRequestEvent(source='looped_assistant', models_usage=RequestUsage(prompt_tokens=75, completion_tokens=15), metadata={}, content=[FunctionCall(id='call_Xqx398CD0LUl6OAxtUYrdu8h', arguments='{\"number\":5}', name='increment_number')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='looped_assistant', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='6', name='increment_number', call_id='call_Xqx398CD0LUl6OAxtUYrdu8h', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='looped_assistant', models_usage=None, metadata={}, content='6', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='looped_assistant', models_usage=RequestUsage(prompt_tokens=98, completion_tokens=15), metadata={}, content=[FunctionCall(id='call_Zgily0MIksJxoOMghtBic8qg', arguments='{\"number\":6}', name='increment_number')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='looped_assistant', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='7', name='increment_number', call_id='call_Zgily0MIksJxoOMghtBic8qg', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='looped_assistant', models_usage=None, metadata={}, content='7', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='looped_assistant', models_usage=RequestUsage(prompt_tokens=121, completion_tokens=14), metadata={}, content=[FunctionCall(id='call_OYmfHXN2SHOpmAk57eRD6I2J', arguments='{\"number\":7}', name='increment_number')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='looped_assistant', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='8', name='increment_number', call_id='call_OYmfHXN2SHOpmAk57eRD6I2J', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='looped_assistant', models_usage=None, metadata={}, content='8', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='looped_assistant', models_usage=RequestUsage(prompt_tokens=144, completion_tokens=15), metadata={}, content=[FunctionCall(id='call_z6B1xM6Br7YSZpEUEN31pKfz', arguments='{\"number\":8}', name='increment_number')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='looped_assistant', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='9', name='increment_number', call_id='call_z6B1xM6Br7YSZpEUEN31pKfz', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='looped_assistant', models_usage=None, metadata={}, content='9', type='ToolCallSummaryMessage'), ToolCallRequestEvent(source='looped_assistant', models_usage=RequestUsage(prompt_tokens=167, completion_tokens=15), metadata={}, content=[FunctionCall(id='call_TaJwx22A9xSwU1DADuLEuTqu', arguments='{\"number\":9}', name='increment_number')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='looped_assistant', models_usage=None, metadata={}, content=[FunctionExecutionResult(content='10', name='increment_number', call_id='call_TaJwx22A9xSwU1DADuLEuTqu', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='looped_assistant', models_usage=None, metadata={}, content='10', type='ToolCallSummaryMessage'), TextMessage(source='looped_assistant', models_usage=RequestUsage(prompt_tokens=190, completion_tokens=14), metadata={}, content='The number has been incremented from 5 to 10.', type='TextMessage')] stop_reason=\"Text message received from 'looped_assistant'\"\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import TextMessageTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY env variable set.\n",
    "    # Disable parallel tool calls for this example.\n",
    "    parallel_tool_calls=False,  # type: ignore\n",
    ")\n",
    "\n",
    "\n",
    "# Create a tool for incrementing a number.\n",
    "def increment_number(number: int) -> int:\n",
    "    \"\"\"Increment a number by 1.\"\"\"\n",
    "    return number + 1\n",
    "\n",
    "\n",
    "# Create a tool agent that uses the increment_number function.\n",
    "looped_assistant = AssistantAgent(\n",
    "    \"looped_assistant\",\n",
    "    model_client=model_client,\n",
    "    tools=[increment_number],  # Register the tool.\n",
    "    system_message=\"You are a helpful AI assistant, use the tool to increment the number.\",\n",
    ")\n",
    "\n",
    "# Termination condition that stops the task if the agent responds with a text message.\n",
    "termination_condition = TextMessageTermination(\"looped_assistant\")\n",
    "\n",
    "# Create a team with the looped assistant agent and the termination condition.\n",
    "team = RoundRobinGroupChat(\n",
    "    [looped_assistant],\n",
    "    termination_condition=termination_condition,\n",
    ")\n",
    "\n",
    "# Run the team with a task and print the messages to the console.\n",
    "async for message in team.run_stream(task=\"Increment the number 5 to 10.\"):  # type: ignore\n",
    "    print(type(message).__name__, message)\n",
    "\n",
    "await model_client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c7272",
   "metadata": {},
   "source": [
    "# Swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9950b55",
   "metadata": {},
   "source": [
    "Similar to **SelectorGroupChat** and **RoundRobinGroupChat**, participant agents broadcast their responses so all agents share the same message context.\n",
    "\n",
    "Different from the other two group chat teams, at each turn, the speaker agent is selected based on the most recent **HandoffMessage** message in the context. This requires each agent in the team to be able to generate HandoffMessage to signal which other agents that it hands off to.\n",
    "\n",
    "For AssistantAgent, you can set the *handoffs* argument to specify which agents it can hand off to. You can use **Handoff** to customize the message content and handoff behavior.\n",
    "\n",
    "**HandoffMessage message** - a message requesting handoff of a conversation to another agent (сообщение с просьбой передать разговор другому агенту)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed9ffcb",
   "metadata": {},
   "source": [
    "The overall process can be summarized as follows:\n",
    "\n",
    "1. Each agent has the ability to generate HandoffMessage to signal which other agents it can hand off to. For AssistantAgent, this means setting the handoffs argument.\n",
    "\n",
    "2. When the team starts on a task, the first speaker agents operate on the task and make localized decision about whether to hand off and to whom.\n",
    "\n",
    "3. When an agent generates a HandoffMessage, the receiving agent takes over the task with the same message context.\n",
    "\n",
    "4. The process continues until a termination condition is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61853f6",
   "metadata": {},
   "source": [
    "The AssistantAgent uses the tool calling capability of the model to generate handoffs. This means that the model must support tool calling. **If the model does parallel tool calling, multiple handoffs may be generated at the same time. This can lead to unexpected behavior.** To avoid this, you can disable parallel tool calling by configuring the model client. For OpenAIChatCompletionClient and AzureOpenAIChatCompletionClient, you can set parallel_tool_calls=False in the configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d18b6",
   "metadata": {},
   "source": [
    "## Customer Support Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe7532",
   "metadata": {},
   "source": [
    "![Example Image](../data/flight_refund.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74b841",
   "metadata": {},
   "source": [
    "This system implements a flights refund scenario with two agents:\n",
    "\n",
    "* **Travel Agent**: Handles general travel and refund coordination.\n",
    "\n",
    "* **Flights Refunder**: Specializes in processing flight refunds with the refund_flight tool.\n",
    "\n",
    "Additionally, we let the user interact with the agents, when agents handoff to \"user\".\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1. The Travel Agent initiates the conversation and evaluates the user’s request.\n",
    "\n",
    "2. Based on the request:\n",
    "\n",
    "    * For refund-related tasks, the Travel Agent hands off to the Flights Refunder.\n",
    "\n",
    "    * For information needed from the customer, either agent can hand off to the \"user\".\n",
    "\n",
    "3. The Flights Refunder processes refunds using the refund_flight tool when appropriate.\n",
    "\n",
    "4. If an agent hands off to the \"user\", the team execution will stop and wait for the user to input a response.\n",
    "\n",
    "5. When the user provides input, it’s sent back to the team as a HandoffMessage. This message is directed to the agent that originally requested user input.\n",
    "\n",
    "6. The process continues until the Travel Agent determines the task is complete and terminates the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097de2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import HandoffTermination, TextMentionTermination\n",
    "from autogen_agentchat.messages import HandoffMessage\n",
    "from autogen_agentchat.teams import Swarm\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007942e",
   "metadata": {},
   "source": [
    "**Tool:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47a323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refund_flight(flight_id: str) -> str:\n",
    "    \"\"\"Refund a flight\"\"\"\n",
    "    return f\"Flight {flight_id} refunded\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57aba2b",
   "metadata": {},
   "source": [
    "**Agents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30f718ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    ")\n",
    "\n",
    "travel_agent = AssistantAgent(\n",
    "    \"travel_agent\",\n",
    "    model_client=model_client,\n",
    "    handoffs=[\"flights_refunder\", \"user\"],\n",
    "    system_message=\"\"\"You are a travel agent.\n",
    "    The flights_refunder is in charge of refunding flights.\n",
    "    If you need information from the user, you must first send your message, then you can handoff to the user.\n",
    "    Use TERMINATE when the travel planning is complete.\"\"\",\n",
    ")\n",
    "\n",
    "flights_refunder = AssistantAgent(\n",
    "    \"flights_refunder\",\n",
    "    model_client=model_client,\n",
    "    handoffs=[\"travel_agent\", \"user\"],\n",
    "    tools=[refund_flight],\n",
    "    system_message=\"\"\"You are an agent specialized in refunding flights.\n",
    "    You only need flight reference numbers to refund a flight.\n",
    "    You have the ability to refund a flight using the refund_flight tool.\n",
    "    If you need information from the user, you must first send your message, then you can handoff to the user.\n",
    "    When the transaction is complete, handoff to the travel agent to finalize.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c7eb447",
   "metadata": {},
   "outputs": [],
   "source": [
    "termination = HandoffTermination(target=\"user\") | TextMentionTermination(\"TERMINATE\")\n",
    "team = Swarm([travel_agent, flights_refunder], termination_condition=termination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16212563",
   "metadata": {},
   "source": [
    "**Running a team:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cfdd120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "I need to refund my flight.\n",
      "---------- TextMessage (travel_agent) ----------\n",
      "I can help with that. Could you please provide me with some details about your flight, such as the booking reference number and the reason for the refund? Once I have that information, I can transfer you to the flights refunder.\n",
      "---------- ToolCallRequestEvent (travel_agent) ----------\n",
      "[FunctionCall(id='call_b6yXuoXdvnqJ4XPKpqUv67m8', arguments='{}', name='transfer_to_user')]\n",
      "---------- ToolCallExecutionEvent (travel_agent) ----------\n",
      "[FunctionExecutionResult(content='Transferred to user, adopting the role of user immediately.', name='transfer_to_user', call_id='call_b6yXuoXdvnqJ4XPKpqUv67m8', is_error=False)]\n",
      "---------- HandoffMessage (travel_agent) ----------\n",
      "Transferred to user, adopting the role of user immediately.\n",
      "---------- HandoffMessage (user) ----------\n",
      "12345\n",
      "---------- ToolCallRequestEvent (travel_agent) ----------\n",
      "[FunctionCall(id='call_2x3zmpth0xN3PfVhiz0KzoX9', arguments='{}', name='transfer_to_flights_refunder')]\n",
      "---------- ToolCallExecutionEvent (travel_agent) ----------\n",
      "[FunctionExecutionResult(content='Transferred to flights_refunder, adopting the role of flights_refunder immediately.', name='transfer_to_flights_refunder', call_id='call_2x3zmpth0xN3PfVhiz0KzoX9', is_error=False)]\n",
      "---------- HandoffMessage (travel_agent) ----------\n",
      "Transferred to flights_refunder, adopting the role of flights_refunder immediately.\n",
      "---------- ToolCallRequestEvent (flights_refunder) ----------\n",
      "[FunctionCall(id='call_wxaaWgvGZ09c5EIvacjiWvhg', arguments='{\"flight_id\":\"12345\"}', name='refund_flight')]\n",
      "---------- ToolCallExecutionEvent (flights_refunder) ----------\n",
      "[FunctionExecutionResult(content='Flight 12345 refunded', name='refund_flight', call_id='call_wxaaWgvGZ09c5EIvacjiWvhg', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (flights_refunder) ----------\n",
      "Flight 12345 refunded\n",
      "---------- ToolCallRequestEvent (flights_refunder) ----------\n",
      "[FunctionCall(id='call_Wjxt6J24sxKUtXRku72a3rr8', arguments='{}', name='transfer_to_travel_agent')]\n",
      "---------- ToolCallExecutionEvent (flights_refunder) ----------\n",
      "[FunctionExecutionResult(content='Transferred to travel_agent, adopting the role of travel_agent immediately.', name='transfer_to_travel_agent', call_id='call_Wjxt6J24sxKUtXRku72a3rr8', is_error=False)]\n",
      "---------- HandoffMessage (flights_refunder) ----------\n",
      "Transferred to travel_agent, adopting the role of travel_agent immediately.\n",
      "---------- TextMessage (travel_agent) ----------\n",
      "Your flight with booking reference number 12345 has been successfully refunded. If there's anything else you need help with, feel free to let me know! Safe travels! TERMINATE\n"
     ]
    }
   ],
   "source": [
    "task = \"I need to refund my flight.\"\n",
    "\n",
    "\n",
    "async def run_team_stream() -> None:\n",
    "    task_result = await Console(team.run_stream(task=task))\n",
    "    last_message = task_result.messages[-1]\n",
    "\n",
    "    while isinstance(last_message, HandoffMessage) and last_message.target == \"user\":\n",
    "        user_message = input(\"User: \")\n",
    "\n",
    "        task_result = await Console(\n",
    "            team.run_stream(task=HandoffMessage(source=\"user\", target=last_message.source, content=user_message))\n",
    "        )\n",
    "        last_message = task_result.messages[-1]\n",
    "\n",
    "\n",
    "# Use asyncio.run(...) if you are running this in a script.\n",
    "await run_team_stream()\n",
    "await model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd3778a",
   "metadata": {},
   "source": [
    "## Stock Research Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9b530",
   "metadata": {},
   "source": [
    "![Example Image](../data/stock_research.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040c1dc1",
   "metadata": {},
   "source": [
    "This system is designed to perform stock research tasks by leveraging four agents:\n",
    "\n",
    "* **Planner**: The central coordinator that delegates specific tasks to specialized agents based on their expertise. The planner ensures that each agent is utilized efficiently and oversees the overall workflow.\n",
    "\n",
    "* **Financial Analyst**: A specialized agent responsible for analyzing financial metrics and stock data using tools such as *get_stock_data*.\n",
    "\n",
    "* **News Analyst**: An agent focused on gathering and summarizing recent news articles relevant to the stock, using tools such as *get_news*.\n",
    "\n",
    "* **Writer**: An agent tasked with compiling the findings from the stock and news analysis into a cohesive final report.\n",
    "\n",
    "**Workflow:**\n",
    "1. The Planner initiates the research process by delegating tasks to the appropriate agents in a step-by-step manner.\n",
    "\n",
    "2. Each agent performs its task independently and appends their work to the **shared message thread/history**. Rather than directly returning results to the planner, all agents contribute to and read from this shared message history. When agents generate their work using the LLM, they have access to this shared message history, which provides context and helps track the overall progress of the task.\n",
    "\n",
    "3. Once an agent completes its task, it hands off control back to the planner.\n",
    "\n",
    "4. The process continues until the planner determines that all necessary tasks have been completed and decides to terminate the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8b572",
   "metadata": {},
   "source": [
    "**Tools:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb85505",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_stock_data(symbol: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get stock market data for a given symbol\"\"\"\n",
    "    return {\"price\": 180.25, \"volume\": 1000000, \"pe_ratio\": 65.4, \"market_cap\": \"700B\"}\n",
    "\n",
    "\n",
    "async def get_news(query: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Get recent news articles about a company\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"title\": \"Tesla Expands Cybertruck Production\",\n",
    "            \"date\": \"2024-03-20\",\n",
    "            \"summary\": \"Tesla ramps up Cybertruck manufacturing capacity at Gigafactory Texas, aiming to meet strong demand.\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Tesla FSD Beta Shows Promise\",\n",
    "            \"date\": \"2024-03-19\",\n",
    "            \"summary\": \"Latest Full Self-Driving beta demonstrates significant improvements in urban navigation and safety features.\",\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Model Y Dominates Global EV Sales\",\n",
    "            \"date\": \"2024-03-18\",\n",
    "            \"summary\": \"Tesla's Model Y becomes best-selling electric vehicle worldwide, capturing significant market share.\",\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943a8b2",
   "metadata": {},
   "source": [
    "**Agents:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe1d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    ")\n",
    "\n",
    "planner = AssistantAgent(\n",
    "    \"planner\",\n",
    "    model_client=model_client,\n",
    "    handoffs=[\"financial_analyst\", \"news_analyst\", \"writer\"],\n",
    "    system_message=\"\"\"You are a research planning coordinator.\n",
    "    Coordinate market research by delegating to specialized agents:\n",
    "    - Financial Analyst: For stock data analysis\n",
    "    - News Analyst: For news gathering and analysis\n",
    "    - Writer: For compiling final report\n",
    "    Always send your plan first, then handoff to appropriate agent.\n",
    "    Always handoff to a single agent at a time.\n",
    "    Use TERMINATE when research is complete.\"\"\",\n",
    ")\n",
    "\n",
    "financial_analyst = AssistantAgent(\n",
    "    \"financial_analyst\",\n",
    "    model_client=model_client,\n",
    "    handoffs=[\"planner\"],\n",
    "    tools=[get_stock_data],\n",
    "    system_message=\"\"\"You are a financial analyst.\n",
    "    Analyze stock market data using the get_stock_data tool.\n",
    "    Provide insights on financial metrics.\n",
    "    Always handoff back to planner when analysis is complete.\"\"\",\n",
    ")\n",
    "\n",
    "news_analyst = AssistantAgent(\n",
    "    \"news_analyst\",\n",
    "    model_client=model_client,\n",
    "    handoffs=[\"planner\"],\n",
    "    tools=[get_news],\n",
    "    system_message=\"\"\"You are a news analyst.\n",
    "    Gather and analyze relevant news using the get_news tool.\n",
    "    Summarize key market insights from news.\n",
    "    Always handoff back to planner when analysis is complete.\"\"\",\n",
    ")\n",
    "\n",
    "writer = AssistantAgent(\n",
    "    \"writer\",\n",
    "    model_client=model_client,\n",
    "    handoffs=[\"planner\"],\n",
    "    system_message=\"\"\"You are a financial report writer.\n",
    "    Compile research findings into clear, concise reports.\n",
    "    Always handoff back to planner when writing is complete.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bab8364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Conduct market research for TSLA stock\n",
      "---------- ThoughtEvent (planner) ----------\n",
      "Here's the plan for conducting market research on TSLA (Tesla) stock:\n",
      "\n",
      "1. **Financial Analysis**: Gather and analyze stock data for Tesla. This includes looking into recent stock performance, trends, and other relevant financial metrics.\n",
      "\n",
      "2. **News Analysis**: Gather and assess the latest news related to Tesla. This includes recent developments, industry news, regulatory updates, and any other information that could impact Tesla's stock performance.\n",
      "\n",
      "3. **Report Compilation**: Compile the insights from the financial and news analysis into a coherent market research report.\n",
      "\n",
      "Let's begin by handing off the task to the Financial Analyst for stock data analysis.\n",
      "---------- ToolCallRequestEvent (planner) ----------\n",
      "[FunctionCall(id='call_W3rexbpUFxCSxvSFvEaaNVNe', arguments='{}', name='transfer_to_financial_analyst')]\n",
      "---------- ToolCallExecutionEvent (planner) ----------\n",
      "[FunctionExecutionResult(content='Transferred to financial_analyst, adopting the role of financial_analyst immediately.', name='transfer_to_financial_analyst', call_id='call_W3rexbpUFxCSxvSFvEaaNVNe', is_error=False)]\n",
      "---------- HandoffMessage (planner) ----------\n",
      "Transferred to financial_analyst, adopting the role of financial_analyst immediately.\n",
      "---------- ToolCallRequestEvent (financial_analyst) ----------\n",
      "[FunctionCall(id='call_TTFe3jYX0wTnT8t8mmSJCEYO', arguments='{\"symbol\":\"TSLA\"}', name='get_stock_data')]\n",
      "---------- ToolCallExecutionEvent (financial_analyst) ----------\n",
      "[FunctionExecutionResult(content=\"{'price': 180.25, 'volume': 1000000, 'pe_ratio': 65.4, 'market_cap': '700B'}\", name='get_stock_data', call_id='call_TTFe3jYX0wTnT8t8mmSJCEYO', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (financial_analyst) ----------\n",
      "{'price': 180.25, 'volume': 1000000, 'pe_ratio': 65.4, 'market_cap': '700B'}\n",
      "---------- ThoughtEvent (financial_analyst) ----------\n",
      "Here is the stock data analysis for Tesla, Inc. (TSLA):\n",
      "\n",
      "1. **Current Stock Price**: Tesla's stock is currently priced at $180.25.\n",
      "\n",
      "2. **Trading Volume**: The trading volume is approximately 1,000,000 shares. Volume can indicate the liquidity of the stock and how often it is being traded in the market.\n",
      "\n",
      "3. **P/E Ratio**: The Price-to-Earnings (P/E) ratio is 65.4. This metric is used to evaluate the valuation of a stock relative to its earnings. A higher P/E ratio suggests that investors may expect higher earnings growth in the future compared to other companies with a lower P/E ratio.\n",
      "\n",
      "4. **Market Capitalization**: Tesla's market cap stands at $700 billion, placing it among the largest companies by market capitalization. This reflects the total market value of the company's outstanding shares and is often used to determine the company's size and investment risk.\n",
      "\n",
      "These financial metrics provide a snapshot of Tesla's current position in the stock market. Next steps typically involve qualitative analysis like reviewing recent news, Tesla's business strategies, competition, and industry developments for a comprehensive analysis.\n",
      "\n",
      "I'll now hand off the task back to the planner for further actions or continuation with other analysis components.\n",
      "---------- ToolCallRequestEvent (financial_analyst) ----------\n",
      "[FunctionCall(id='call_EkewQELatobwh9ZEUNUegSZn', arguments='{}', name='transfer_to_planner')]\n",
      "---------- ToolCallExecutionEvent (financial_analyst) ----------\n",
      "[FunctionExecutionResult(content='Transferred to planner, adopting the role of planner immediately.', name='transfer_to_planner', call_id='call_EkewQELatobwh9ZEUNUegSZn', is_error=False)]\n",
      "---------- HandoffMessage (financial_analyst) ----------\n",
      "Transferred to planner, adopting the role of planner immediately.\n",
      "---------- ThoughtEvent (planner) ----------\n",
      "The financial analysis of TSLA stock has been completed with the following key insights: current stock price, trading volume, P/E ratio, and market capitalization.\n",
      "\n",
      "Next, we will move to news gathering and analysis to understand recent developments related to Tesla that could impact its stock performance.\n",
      "\n",
      "I'll hand off this next part to the News Analyst.\n",
      "---------- ToolCallRequestEvent (planner) ----------\n",
      "[FunctionCall(id='call_d9ji5hPO4p7hPInL9D2KDhgc', arguments='{}', name='transfer_to_news_analyst')]\n",
      "---------- ToolCallExecutionEvent (planner) ----------\n",
      "[FunctionExecutionResult(content='Transferred to news_analyst, adopting the role of news_analyst immediately.', name='transfer_to_news_analyst', call_id='call_d9ji5hPO4p7hPInL9D2KDhgc', is_error=False)]\n",
      "---------- HandoffMessage (planner) ----------\n",
      "Transferred to news_analyst, adopting the role of news_analyst immediately.\n",
      "---------- ToolCallRequestEvent (news_analyst) ----------\n",
      "[FunctionCall(id='call_FA0pJ4RLTG2bFp8RMvh9rfV5', arguments='{\"query\":\"Tesla\"}', name='get_news')]\n",
      "---------- ToolCallExecutionEvent (news_analyst) ----------\n",
      "[FunctionExecutionResult(content='[{\\'title\\': \\'Tesla Expands Cybertruck Production\\', \\'date\\': \\'2024-03-20\\', \\'summary\\': \\'Tesla ramps up Cybertruck manufacturing capacity at Gigafactory Texas, aiming to meet strong demand.\\'}, {\\'title\\': \\'Tesla FSD Beta Shows Promise\\', \\'date\\': \\'2024-03-19\\', \\'summary\\': \\'Latest Full Self-Driving beta demonstrates significant improvements in urban navigation and safety features.\\'}, {\\'title\\': \\'Model Y Dominates Global EV Sales\\', \\'date\\': \\'2024-03-18\\', \\'summary\\': \"Tesla\\'s Model Y becomes best-selling electric vehicle worldwide, capturing significant market share.\"}]', name='get_news', call_id='call_FA0pJ4RLTG2bFp8RMvh9rfV5', is_error=False)]\n",
      "---------- ToolCallSummaryMessage (news_analyst) ----------\n",
      "[{'title': 'Tesla Expands Cybertruck Production', 'date': '2024-03-20', 'summary': 'Tesla ramps up Cybertruck manufacturing capacity at Gigafactory Texas, aiming to meet strong demand.'}, {'title': 'Tesla FSD Beta Shows Promise', 'date': '2024-03-19', 'summary': 'Latest Full Self-Driving beta demonstrates significant improvements in urban navigation and safety features.'}, {'title': 'Model Y Dominates Global EV Sales', 'date': '2024-03-18', 'summary': \"Tesla's Model Y becomes best-selling electric vehicle worldwide, capturing significant market share.\"}]\n",
      "---------- ThoughtEvent (news_analyst) ----------\n",
      "Here are the recent news highlights related to Tesla (TSLA):\n",
      "\n",
      "1. **Tesla Expands Cybertruck Production** (March 20, 2024)\n",
      "   - Tesla is ramping up Cybertruck manufacturing capacity at its Gigafactory in Texas to meet the strong demand for the vehicle.\n",
      "\n",
      "2. **Tesla FSD Beta Shows Promise** (March 19, 2024)\n",
      "   - The latest version of Tesla's Full Self-Driving (FSD) beta has shown significant improvements in urban navigation and safety features, boosting confidence in Tesla's autonomous vehicle technology.\n",
      "\n",
      "3. **Model Y Dominates Global EV Sales** (March 18, 2024)\n",
      "   - Tesla's Model Y has become the best-selling electric vehicle (EV) worldwide, capturing a significant share of the market and highlighting Tesla's leadership position in the EV sector.\n",
      "\n",
      "These news updates reflect Tesla's ongoing efforts to expand its product offerings, enhance its technology, and maintain a dominant position in the electric vehicle market. Such developments can positively influence investor sentiment and potentially impact Tesla's stock performance.\n",
      "\n",
      "Market insights from the news and financial analysis have been gathered. I'll hand off back to the planner to decide any further actions or compile a comprehensive report.\n",
      "---------- ToolCallRequestEvent (news_analyst) ----------\n",
      "[FunctionCall(id='call_l2mDCoz4g7pc6sVIS5QvN19A', arguments='{}', name='transfer_to_planner')]\n",
      "---------- ToolCallExecutionEvent (news_analyst) ----------\n",
      "[FunctionExecutionResult(content='Transferred to planner, adopting the role of planner immediately.', name='transfer_to_planner', call_id='call_l2mDCoz4g7pc6sVIS5QvN19A', is_error=False)]\n",
      "---------- HandoffMessage (news_analyst) ----------\n",
      "Transferred to planner, adopting the role of planner immediately.\n",
      "---------- ThoughtEvent (planner) ----------\n",
      "The news analysis on Tesla has been completed, highlighting key developments such as the expansion of Cybertruck production, improvements in Tesla's Full Self-Driving technology, and the dominance of Model Y in global EV sales.\n",
      "\n",
      "With both the financial and news analysis complete, we will now move on to compiling a comprehensive market research report.\n",
      "\n",
      "I'll hand off this task to the Writer to compile all insights into the final report.\n",
      "---------- ToolCallRequestEvent (planner) ----------\n",
      "[FunctionCall(id='call_HVfuWf6wXgoM4dkxtaKIK71w', arguments='{}', name='transfer_to_writer')]\n",
      "---------- ToolCallExecutionEvent (planner) ----------\n",
      "[FunctionExecutionResult(content='Transferred to writer, adopting the role of writer immediately.', name='transfer_to_writer', call_id='call_HVfuWf6wXgoM4dkxtaKIK71w', is_error=False)]\n",
      "---------- HandoffMessage (planner) ----------\n",
      "Transferred to writer, adopting the role of writer immediately.\n",
      "---------- TextMessage (writer) ----------\n",
      "### Tesla (TSLA) Market Research Report\n",
      "\n",
      "#### Financial Analysis\n",
      "\n",
      "- **Current Stock Price**: $180.25\n",
      "- **Trading Volume**: Approximately 1,000,000 shares. This indicates active trading and a relatively liquid market for Tesla shares.\n",
      "- **P/E Ratio**: 65.4, suggesting that investors are optimistic about Tesla's future earnings growth compared to other companies.\n",
      "- **Market Capitalization**: $700 billion, positioning Tesla among the largest companies by market cap, which reflects market perception of its strong positioning in the electric vehicle market.\n",
      "\n",
      "#### News Analysis\n",
      "\n",
      "1. **Cybertruck Production Expansion**:\n",
      "   - Tesla is increasing its production capacity for the Cybertruck at Gigafactory Texas to meet strong market demand. This expansion indicates Tesla's proactive strategies to capitalize on its innovative product lineup.\n",
      "\n",
      "2. **Advancements in Full Self-Driving (FSD) Technology**:\n",
      "   - Recent developments in Tesla's FSD beta version have shown substantial improvements, particularly in urban navigation and safety. This advancement reinforces Tesla's leadership in autonomous vehicle technology, potentially driving long-term growth and investor interest.\n",
      "\n",
      "3. **Model Y Leads Global EV Market**:\n",
      "   - The Model Y has emerged as the best-selling electric vehicle globally, highlighting Tesla's dominance in the EV industry. This achievement not only reflects consumer trust in Tesla's brand but also underscores the company's ability to maintain its market leadership amidst rising competition.\n",
      "\n",
      "#### Conclusion\n",
      "\n",
      "Tesla continues to demonstrate strong performance both in the stock market and the electric vehicle sector. The financial indicators suggest a positive investor outlook, while recent news highlights assert Tesla's commitment to innovation and market dominance. Tesla's strategic expansions and technological advancements in autonomous driving make it a potentially attractive option for investors seeking growth opportunities in the EV market.\n",
      "\n",
      "The report is now complete, and I will hand this back to the planner for any further actions or finalization.\n",
      "---------- ToolCallRequestEvent (writer) ----------\n",
      "[FunctionCall(id='call_laQGxiUbY2c7Cvs6yc9iWaI4', arguments='{}', name='transfer_to_planner')]\n",
      "---------- ToolCallExecutionEvent (writer) ----------\n",
      "[FunctionExecutionResult(content='Transferred to planner, adopting the role of planner immediately.', name='transfer_to_planner', call_id='call_laQGxiUbY2c7Cvs6yc9iWaI4', is_error=False)]\n",
      "---------- HandoffMessage (writer) ----------\n",
      "Transferred to planner, adopting the role of planner immediately.\n",
      "---------- TextMessage (planner) ----------\n",
      "The market research report on Tesla (TSLA) has been successfully compiled. The report includes key insights from both financial and news analysis, highlighting Tesla's stock performance, recent developments in production and technology, and its market dominance.\n",
      "\n",
      "Since the research and reporting process is complete, I'll proceed to finalize the task. \n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "# Define termination condition\n",
    "text_termination = TextMentionTermination(\"TERMINATE\")\n",
    "termination = text_termination\n",
    "\n",
    "research_team = Swarm(\n",
    "    participants=[planner, financial_analyst, news_analyst, writer], termination_condition=termination\n",
    ")\n",
    "\n",
    "task = \"Conduct market research for TSLA stock\"\n",
    "await Console(research_team.run_stream(task=task))\n",
    "await model_client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

dialogue2graph.metrics.no_llm_metrics.keys2graph.metrics_annotation
===================================================================

.. py:module:: dialogue2graph.metrics.no_llm_metrics.keys2graph.metrics_annotation

.. autoapi-nested-parse::

   Module to compare annotation-level similarity between original and generated graphs.

   For each key in the annotation:
   - If both are numeric, compute absolute difference.
   - If both are text (not unknown), compute semantic similarity (cosine).
   - If either is "unknown", skip from accuracy. We'll track them separately.

   We return per-key stats and then aggregated stats.



Functions
---------

.. autoapisummary::

   dialogue2graph.metrics.no_llm_metrics.keys2graph.metrics_annotation.is_numeric
   dialogue2graph.metrics.no_llm_metrics.keys2graph.metrics_annotation.compare_annotation_differences


Module Contents
---------------

.. py:function:: is_numeric(val) -> bool

.. py:function:: compare_annotation_differences(ann_original: Dict[str, Any], ann_generated: Dict[str, Any]) -> Dict[str, Any]

   Compare two annotation dictionaries (like ann_original, ann_generated).
   Return detailed and summary stats:

   {
     "per_key": {
        "topic": {"orig": "...", "gen": "...", "score": 1.0, "difference": 0.0, "is_unknown": False, ...},
        ...
     },
     "summary": {
        "avg_score": 0.XX,
        "avg_difference": 0.XX,
        "count_keys_compared": X,
        "count_unknowns": Y,
        "unknown_keys": [...]
     }
   }



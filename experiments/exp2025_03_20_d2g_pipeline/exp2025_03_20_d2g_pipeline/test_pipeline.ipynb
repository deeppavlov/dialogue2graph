{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "os.environ['PATH_TO_ENV'] = \"~/projects/chatsky-llm-autoconfig/.env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.pipelines.models import ModelsAPI\n",
    "models = ModelsAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2G Algo pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.pipelines.d2g_algo.pipeline import Pipeline\n",
    "filling_llm = models(\"llm\", name=\"o3-mini\", temp=1)\n",
    "formatting_llm = models(\"llm\", name=\"gpt-4o-mini\", temp=0)\n",
    "sim_model = models(\"similarity\", name=\"BAAI/bge-m3\", device=\"cuda:0\")\n",
    "pipeline = Pipeline(filling_llm, formatting_llm, sim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': \"No, I'll manage on my own.\", 'participant': 'user'},\n",
    "   {'text': 'No worries! Feel free to reach out anytime.',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Alright, thanks anyway.', 'participant': 'user'},\n",
    "   {'text': \"You're welcome! Have a fantastic trip!\",\n",
    "    'participant': 'assistant'}]\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Actually, never mind.', 'participant': 'user'},\n",
    "   {'text': 'Alright, let me know if you need help later. Have a great day!',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Okay, have a great day!', 'participant': 'user'},\n",
    "   {'text': 'Glad to help! Safe travels.', 'participant': 'assistant'}],\n",
    "   [{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': \"No, I'll manage on my own.\", 'participant': 'user'},\n",
    "   {'text': 'No worries! Feel free to reach out anytime.',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Alright, thanks anyway.', 'participant': 'user'},\n",
    "   {'text': \"You're welcome! Have a fantastic trip!\",\n",
    "    'participant': 'assistant'}]]\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"messages\": [{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': \"No, I'll manage on my own.\", 'participant': 'user'},\n",
    "   {'text': 'No worries! Feel free to reach out anytime.',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Alright, thanks anyway.', 'participant': 'user'},\n",
    "   {'text': \"You're welcome! Have a fantastic trip!\",\n",
    "    'participant': 'assistant'}]}]\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transfer.json') as f:\n",
    "    data = json.load(f)\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pipeline.invoke(\"transfer.json\")\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2G LLM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.pipelines.d2g_llm.pipeline import Pipeline\n",
    "grouping_llm = models(\"llm\", name=\"chatgpt-4o-latest\", temp=0)\n",
    "filling_llm = models(\"llm\", name=\"o3-mini\", temp=1)\n",
    "formatting_llm = models(\"llm\", name=\"gpt-4o-mini\", temp=0)\n",
    "sim_model = models(\"similarity\", name=\"BAAI/bge-m3\", device=\"cuda:0\")\n",
    "pipeline = Pipeline(grouping_llm, filling_llm, formatting_llm, sim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': \"No, I'll manage on my own.\", 'participant': 'user'},\n",
    "   {'text': 'No worries! Feel free to reach out anytime.',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Alright, thanks anyway.', 'participant': 'user'},\n",
    "   {'text': \"You're welcome! Have a fantastic trip!\",\n",
    "    'participant': 'assistant'}]\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Actually, never mind.', 'participant': 'user'},\n",
    "   {'text': 'Alright, let me know if you need help later. Have a great day!',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Okay, have a great day!', 'participant': 'user'},\n",
    "   {'text': 'Glad to help! Safe travels.', 'participant': 'assistant'}],\n",
    "   [{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': \"No, I'll manage on my own.\", 'participant': 'user'},\n",
    "   {'text': 'No worries! Feel free to reach out anytime.',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Alright, thanks anyway.', 'participant': 'user'},\n",
    "   {'text': \"You're welcome! Have a fantastic trip!\",\n",
    "    'participant': 'assistant'}]]\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"messages\": [{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': \"No, I'll manage on my own.\", 'participant': 'user'},\n",
    "   {'text': 'No worries! Feel free to reach out anytime.',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Alright, thanks anyway.', 'participant': 'user'},\n",
    "   {'text': \"You're welcome! Have a fantastic trip!\",\n",
    "    'participant': 'assistant'}]}]\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transfer.json') as f:\n",
    "    data = json.load(f)\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pipeline.invoke(\"transfer.json\")\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for a in range(20)[0:10:2]:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2G LLM extender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.pipelines.d2g_extender.pipeline import Pipeline\n",
    "extending_llm = models(\"llm\", name=\"chatgpt-4o-latest\", temp=0)\n",
    "filling_llm = models(\"llm\", name=\"o3-mini\", temp=1)\n",
    "formatting_llm = models(\"llm\", name=\"gpt-4o-mini\", temp=0)\n",
    "sim_model = models(\"similarity\", name=\"BAAI/bge-m3\", device=\"cuda:0\")\n",
    "pipeline = Pipeline(extending_llm, filling_llm, formatting_llm, sim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': \"No, I'll manage on my own.\", 'participant': 'user'},\n",
    "   {'text': 'No worries! Feel free to reach out anytime.',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Alright, thanks anyway.', 'participant': 'user'},\n",
    "   {'text': \"You're welcome! Have a fantastic trip!\",\n",
    "    'participant': 'assistant'}]\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Actually, never mind.', 'participant': 'user'},\n",
    "   {'text': 'Alright, let me know if you need help later. Have a great day!',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Okay, have a great day!', 'participant': 'user'},\n",
    "   {'text': 'Glad to help! Safe travels.', 'participant': 'assistant'}],\n",
    "   [{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': \"No, I'll manage on my own.\", 'participant': 'user'},\n",
    "   {'text': 'No worries! Feel free to reach out anytime.',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Alright, thanks anyway.', 'participant': 'user'},\n",
    "   {'text': \"You're welcome! Have a fantastic trip!\",\n",
    "    'participant': 'assistant'}]]\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"messages\": [{'text': 'Hey there! How can I help you today?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'I need to book a ride to the airport.', 'participant': 'user'},\n",
    "   {'text': 'Sure! I can help with that. When is your flight, and where are you departing from?',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Do you have any other options?', 'participant': 'user'},\n",
    "   {'text': \"If you'd prefer, I can send you options for ride-share services instead. Would you like that?\",\n",
    "    'participant': 'assistant'},\n",
    "   {'text': \"No, I'll manage on my own.\", 'participant': 'user'},\n",
    "   {'text': 'No worries! Feel free to reach out anytime.',\n",
    "    'participant': 'assistant'},\n",
    "   {'text': 'Alright, thanks anyway.', 'participant': 'user'},\n",
    "   {'text': \"You're welcome! Have a fantastic trip!\",\n",
    "    'participant': 'assistant'}]}]\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transfer.json') as f:\n",
    "    data = json.load(f)\n",
    "graph = pipeline.invoke(data)\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pipeline.invoke(\"transfer.json\")\n",
    "graph.visualise_short(\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_metrics_data.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.pipelines.core.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph(data[2]['graph']).visualise_short(\"What\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edges': [{'source': 2,\n",
       "   'target': 3,\n",
       "   'utterances': [\"Yes, I checked but it still doesn't sync.\"]},\n",
       "  {'source': 3,\n",
       "   'target': 4,\n",
       "   'utterances': ['Alright, please guide me through the steps.']},\n",
       "  {'source': 4,\n",
       "   'target': 6,\n",
       "   'utterances': [\"I've followed the steps and it seems to be working now.\"]},\n",
       "  {'source': 2,\n",
       "   'target': 8,\n",
       "   'utterances': [\"I think I'll handle it later. Thanks anyway.\"]},\n",
       "  {'source': 4,\n",
       "   'target': 7,\n",
       "   'utterances': ['I want to change the time zone instead.']},\n",
       "  {'source': 7,\n",
       "   'target': 4,\n",
       "   'utterances': [\"Sure, let's adjust the time zone settings.\"]},\n",
       "  {'source': 5,\n",
       "   'target': 6,\n",
       "   'utterances': [\"After adjusting, it still doesn't sync.\"]},\n",
       "  {'source': 3,\n",
       "   'target': 5,\n",
       "   'utterances': ['Time zone settings are correct, but the issue persists.']},\n",
       "  {'source': 6,\n",
       "   'target': 8,\n",
       "   'utterances': [\"Actually, it's still not syncing. I want to try something else.\"]}],\n",
       " 'nodes': [{'id': 2,\n",
       "   'label': 'identify_issue',\n",
       "   'is_start': False,\n",
       "   'utterances': [\"I'm sorry to hear you're experiencing a sync delay. Can you tell me more about the issue?\"]},\n",
       "  {'id': 3,\n",
       "   'label': 'ask_time_zone',\n",
       "   'is_start': False,\n",
       "   'utterances': ['Could you verify that the time zone settings are properly configured on your devices?',\n",
       "    'Have you checked if your time zone settings are correct on all your devices?']},\n",
       "  {'id': 4,\n",
       "   'label': 'provide_steps',\n",
       "   'is_start': False,\n",
       "   'utterances': ['Sure, let me guide you through adjusting your time zone settings.']},\n",
       "  {'id': 5,\n",
       "   'label': 'alternative_solution',\n",
       "   'is_start': False,\n",
       "   'utterances': ['If time zone settings are correct, we can try refreshing the calendar app or reinstalling it.']},\n",
       "  {'id': 6,\n",
       "   'label': 'confirm_resolution',\n",
       "   'is_start': False,\n",
       "   'utterances': ['Great! Is your calendar syncing correctly now?']},\n",
       "  {'id': 7,\n",
       "   'label': 'modify_time_zone',\n",
       "   'is_start': False,\n",
       "   'utterances': ['Of course! Which device would you like to adjust the time zone settings on?']},\n",
       "  {'id': 8,\n",
       "   'label': 'exit_conversation',\n",
       "   'is_start': False,\n",
       "   'utterances': [\"I'm sorry we couldn't resolve the issue. If you need further assistance, feel free to reach out anytime. Have a great day!\"]}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]['graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph(data[0]['graph']).visualise_short(\"What\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has all the dialogues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is_same_structure': False,\n",
       " 'graph_match': {'value': False,\n",
       "  'description': 'Numbers of nodes do not match: 7 != 8'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.invoke(data[2]['dialogues'], Graph(data[0]['graph']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph has all the dialogues\n"
     ]
    }
   ],
   "source": [
    "graph = pipeline.invoke(data[0]['dialogues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.visualise_short(\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph(data[0]['graph']).visualise_short(\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.invoke(data[0]['dialogues'], Graph(data[0]['graph']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

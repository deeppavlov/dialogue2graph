{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fba93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"validate\" in \"Dialogue\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dialogue2graph.metrics.no_llm_metrics.metrics import (\n",
    "    match_roles_multi_utterance,\n",
    "    is_correct_length_multi_utterance\n",
    ")\n",
    "import json\n",
    "\n",
    "from dialogue2graph.pipelines.model_storage import ModelStorage\n",
    "from dialogue2graph.datasets.augment_dialogues.prompts import augmentation_prompt_3_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3bfe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.pipelines.core.dialogue import DialogueMessage, Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633ad4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/gen_dataset_augmented_0-402_nodes_edges_v5.json', \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "example = data[0]\n",
    "dialogues = example['dialogues']\n",
    "augmented_dialogues = example['augmented_dialogues']\n",
    "\n",
    "dia = dialogues[0]\n",
    "aug_dia = augmented_dialogues[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77813bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 15:22:20,180 - dialogue2graph.pipelines.model_storage - INFO - Added llm model 'generation-llm' to storage\n",
      "2025-04-11 15:22:20,248 - dialogue2graph.pipelines.model_storage - INFO - Added llm model 'formatting-llm' to storage\n"
     ]
    }
   ],
   "source": [
    "# Initialize model storage\n",
    "model_storage = ModelStorage()\n",
    "\n",
    "# Add models to storage\n",
    "model_storage.add(\n",
    "    key=\"generation-llm\",\n",
    "    config={\"model_name\": \"gpt-4o-mini-2024-07-18\", \"temperature\": 0.7},\n",
    "    model_type=\"llm\"\n",
    ")\n",
    "\n",
    "model_storage.add(\n",
    "    key=\"formatting-llm\", \n",
    "    config={\"model_name\": \"gpt-3.5-turbo\", \"temperature\": 0.7},\n",
    "    model_type=\"llm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf058a",
   "metadata": {},
   "source": [
    "## augmentaion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b519bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.datasets.augment_dialogues.augmentation import DialogueAugmenter as DialogueAugmenter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fbbc82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DialogueAugmenter(model_storage=ModelStorage(storage={'generation-llm': StoredData(key='generation-llm', config={'model_name': 'gpt-4o-mini-2024-07-18', 'temperature': 0.7}, model_type='llm', model=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa63f59cc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa63ccdf550>, root_client=<openai.OpenAI object at 0x7fa63f591910>, root_async_client=<openai.AsyncOpenAI object at 0x7fa63ccda290>, model_name='gpt-4o-mini-2024-07-18', model_kwargs={}, openai_api_key=SecretStr('**********'))), 'formatting-llm': StoredData(key='formatting-llm', config={'model_name': 'gpt-3.5-turbo', 'temperature': 0.7}, model_type='llm', model=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fa63cd090d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fa63cd0ddd0>, root_client=<openai.OpenAI object at 0x7fa63ccf4a90>, root_async_client=<openai.AsyncOpenAI object at 0x7fa63cd09290>, model_kwargs={}, openai_api_key=SecretStr('**********')))}), generation_llm='generation-llm', formatting_llm='formatting-llm')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmenter = DialogueAugmenter_(\n",
    "    model_storage=model_storage,\n",
    "    generation_llm=\"generation-llm\",\n",
    "    formatting_llm=\"formatting-llm\"\n",
    ")\n",
    "augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1ea18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:23:43,333 - httpx - INFO - HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'participant': 'assistant',\n",
       "  'text': ['Hello! How can I help you today?',\n",
       "   'Hi! What assistance do you need today?',\n",
       "   'Hey there! How can I support you today?']},\n",
       " {'participant': 'user',\n",
       "  'text': ['I’d like to make a purchase.',\n",
       "   'I want to place an order for something.',\n",
       "   \"I'm looking to order a product.\"]},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Awesome! Which item are you interested in?',\n",
       "   'Sounds good! What product do you have in mind?',\n",
       "   'Fantastic! What would you like to order?']},\n",
       " {'participant': 'user',\n",
       "  'text': [\"I'm interested in a t-shirt.\",\n",
       "   'I’d like to order a t-shirt.',\n",
       "   'I want to get a t-shirt.']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['What size do you need?',\n",
       "   'Could you tell me your size?',\n",
       "   'Which size would you prefer?']},\n",
       " {'participant': 'user',\n",
       "  'text': ['Medium would be great.',\n",
       "   'I’ll go with medium, please.',\n",
       "   'I’d like a medium size.']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Do you want that in red or blue?',\n",
       "   'Would you prefer it in red or blue?',\n",
       "   'Should I get that in red or blue?']},\n",
       " {'participant': 'user',\n",
       "  'text': [\"I'd like the red one, please.\",\n",
       "   'Red sounds good to me.',\n",
       "   \"I'll take it in red, please.\"]},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Great choice! Can you provide me with your shipping address?',\n",
       "   'Perfect! May I have your shipping address?',\n",
       "   'Awesome! What’s your shipping address?']},\n",
       " {'participant': 'user',\n",
       "  'text': [\"It's 123 Main St.\",\n",
       "   'Sure, my address is 123 Main St.',\n",
       "   'The address is 123 Main St.']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Thanks! Your order is confirmed. Is there anything else you need?',\n",
       "   'Thank you! Your order has been successfully placed. Can I help you with anything else?',\n",
       "   'Appreciate it! Your order is on its way. Do you need any further assistance?']},\n",
       " {'participant': 'user',\n",
       "  'text': ['Actually, can I modify my order?',\n",
       "   'Is it possible to change my order?',\n",
       "   'Can I make a change to my order?']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Sure! What would you like to adjust?',\n",
       "   'Absolutely! What changes do you want to make?',\n",
       "   'Of course! What do you want to change in your order?']},\n",
       " {'participant': 'user',\n",
       "  'text': ['I would like to change it to a large size.',\n",
       "   'I want to switch to a large size.',\n",
       "   'Please change it to a large size.']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['What size do you prefer?',\n",
       "   'Can you confirm the size you want?',\n",
       "   'Which size do you choose now?']},\n",
       " {'participant': 'user',\n",
       "  'text': ['Medium, please.',\n",
       "   'Still medium, thank you.',\n",
       "   'I’ll stick with medium, please.']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Should I get that in red or blue?',\n",
       "   'Would you like that in red or blue?',\n",
       "   'Do you want the medium in red or blue?']},\n",
       " {'participant': 'user',\n",
       "  'text': ['Red, please.', 'I’d like that in red.', 'Red works for me.']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Great! Can I have your shipping address again?',\n",
       "   'Awesome choice! Can you share your shipping address?',\n",
       "   'Perfect! What is your shipping address?']},\n",
       " {'participant': 'user',\n",
       "  'text': [\"It's still 123 Main St.\",\n",
       "   'The address remains 123 Main St.',\n",
       "   'You can use 123 Main St. again.']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Thanks for that! Your order is confirmed again. Anything else I can do for you?',\n",
       "   'Thank you! Your order has been updated. Is there anything else I can assist you with?',\n",
       "   'Appreciate it! Your order is now updated. Do you need help with anything else?']},\n",
       " {'participant': 'user',\n",
       "  'text': [\"No, that's everything. Thank you.\",\n",
       "   'That’s all for now. Thanks a lot!',\n",
       "   'Nope, that’s all I need. Thank you!']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Alright, feel free to message anytime. Have a wonderful day!',\n",
       "   \"Okay! Don't hesitate to reach out if you need anything. Have a great day!\",\n",
       "   'Sounds good! Reach out whenever you need assistance. Enjoy your day!']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = augmenter.invoke(\n",
    "    dialogue=dia['messages'],\n",
    "    topic=example['topic'],\n",
    "    prompt=augmentation_prompt_3_vars\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dia = {\"id\": 1, \"messages\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56575b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_roles_multi_utterance(dia, aug_dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16c264fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_correct_length_multi_utterance(dia, aug_dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "837e9f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 15:24:57,040 - httpx - INFO - HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m augmenter\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m      2\u001b[0m     dialogue\u001b[38;5;241m=\u001b[39mdia,\n\u001b[1;32m      3\u001b[0m     topic\u001b[38;5;241m=\u001b[39mexample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     prompt\u001b[38;5;241m=\u001b[39maugmentation_prompt_3_vars\n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m/cephfs/home/olshevskaya/chatsky-llm-autoconfig/dialogue2graph/datasets/augment_dialogues/augmentation.py:102\u001b[0m, in \u001b[0;36mDialogueAugmenter.evaluate\u001b[0;34m(self, dialogue, topic, prompt, report_type)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(augmented_dialogue, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: augmented_dialogue\n\u001b[1;32m     99\u001b[0m         } \u001b[38;5;28;01mif\u001b[39;00m report_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m: augmented_dialogue}])\n\u001b[1;32m    101\u001b[0m report \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_roles\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmatch_roles_multi_utterance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialogue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmented_dialogue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_correct_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: is_correct_length_multi_utterance(dialogue, augmented_dialogue)\n\u001b[1;32m    104\u001b[0m }\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m report_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    107\u001b[0m     report \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(report, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/cephfs/home/olshevskaya/chatsky-llm-autoconfig/dialogue2graph/metrics/no_llm_metrics/metrics.py:540\u001b[0m, in \u001b[0;36mmatch_roles_multi_utterance\u001b[0;34m(D1, D2)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmatch_roles_multi_utterance\u001b[39m(D1: \u001b[38;5;28mdict\u001b[39m, D2: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    533\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03m    Checks if two dialogues have identical participant roles in each turn.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;124;03m    Returns True if they match in every turn, otherwise False.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m    in which the \"text\" key in each message contains a list of augmented phrases.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m phrase_1, phrase_2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(D1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mD2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m phrase_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticipant\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m phrase_2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticipant\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    542\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "report = await augmenter.evaluate(\n",
    "    dialogue=dia,\n",
    "    topic=example['topic'],\n",
    "    prompt=augmentation_prompt_3_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e7955e",
   "metadata": {},
   "source": [
    "## augmentation_corrected.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f345e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue2graph.datasets.augment_dialogues.augmentation_corrected import DialogueAugmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ab4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue = Dialogue.from_list(dia['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759be27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = DialogueAugmenter(\n",
    "    model_storage=model_storage,\n",
    "    generation_llm=\"generation-llm\",\n",
    "    formatting_llm=\"formatting-llm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5e2f597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 13:37:57,286 - httpx - INFO - HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = augmenter.invoke(\n",
    "    dialogue=dialogue,\n",
    "    topic=example['topic'],\n",
    "    prompt=augmentation_prompt_3_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc346939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'participant': 'assistant',\n",
       "  'text': ['Hello! How can I help you today?',\n",
       "   'Hi! What can I do for you today?',\n",
       "   'Hey there! Need assistance with something?']},\n",
       " {'participant': 'user',\n",
       "  'text': ['I’d like to make an order.',\n",
       "   'I want to place an order for something.',\n",
       "   'I’m looking to order a product.']},\n",
       " {'participant': 'assistant',\n",
       "  'text': ['Awesome! Which product are you looking to buy?',\n",
       "   \"That's great! What item are you interested in?\",\n",
       "   'Fantastic! What would you like to order?']}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "525d005e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_dia = {\"id\": 1, \"messages\": result}\n",
    "match_roles_multi_utterance(dia, aug_dia), is_correct_length_multi_utterance(dia, aug_dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bda4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 15:22:44,503 - httpx - INFO - HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "report = await augmenter.evaluate(\n",
    "    dialogue=dialogue,\n",
    "    topic=example['topic'],\n",
    "    prompt=augmentation_prompt_3_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80bef84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'match_roles': True, 'correct_length': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

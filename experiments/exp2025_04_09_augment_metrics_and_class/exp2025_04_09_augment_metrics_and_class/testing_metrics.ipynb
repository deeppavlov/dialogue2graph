{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96fba93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"validate\" in \"Dialogue\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dialogue2graph.metrics.no_llm_metrics.metrics import (\n",
    "    match_roles_multi_utterance,\n",
    "    is_correct_length_multi_utterance\n",
    ")\n",
    "import json\n",
    "\n",
    "from dialogue2graph.datasets.augment_dialogues.augmentation import DialogueAugmenter\n",
    "from dialogue2graph.pipelines.model_storage import ModelStorage\n",
    "from dialogue2graph.datasets.augment_dialogues.prompts import augmentation_prompt_3_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "633ad4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/gen_dataset_augmented_0-402_nodes_edges_v5.json', \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "example = data[0]\n",
    "dialogues = example['dialogues']\n",
    "augmented_dialogues = example['augmented_dialogues']\n",
    "\n",
    "D1 = dialogues[0]\n",
    "D2 = augmented_dialogues[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77813bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 16:57:42,574 - dialogue2graph.pipelines.model_storage - INFO - Added llm model 'generation-llm' to storage\n",
      "2025-04-10 16:57:42,641 - dialogue2graph.pipelines.model_storage - INFO - Added llm model 'formatting-llm' to storage\n"
     ]
    }
   ],
   "source": [
    "# Initialize model storage\n",
    "model_storage = ModelStorage()\n",
    "\n",
    "# # Configure your LLMs\n",
    "# gpt4o_config = {\n",
    "#     \"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "#     \"temperature\": 0.7,\n",
    "#     \"max_tokens\": 2000\n",
    "# }\n",
    "\n",
    "# gpt35_config = {\n",
    "#     \"model\": \"gpt-3.5-turbo\",\n",
    "#     \"temperature\": 0.3,\n",
    "#     \"max_tokens\": 1000\n",
    "# }\n",
    "\n",
    "# Add models to storage\n",
    "# model_storage.add(\n",
    "#     key=\"generation-llm\",\n",
    "#     config=gpt4o_config,\n",
    "#     model_type=\"llm\"\n",
    "# )\n",
    "\n",
    "# model_storage.add(\n",
    "#     key=\"formatting-llm\", \n",
    "#     config=gpt35_config,\n",
    "#     model_type=\"llm\"\n",
    "# )\n",
    "\n",
    "# Add models to storage\n",
    "model_storage.add(\n",
    "    key=\"generation-llm\",\n",
    "    config={\"model_name\": \"chatgpt-4o-latest\", \"temperature\": 0.7},\n",
    "    model_type=\"llm\"\n",
    ")\n",
    "\n",
    "model_storage.add(\n",
    "    key=\"formatting-llm\", \n",
    "    config={\"model_name\": \"chatgpt-4o-latest\", \"temperature\": 0.7},\n",
    "    model_type=\"llm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a309d458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generation-llm': StoredData(key='generation-llm', config={'model_name': 'chatgpt-4o-latest', 'temperature': 0.7}, model_type='llm', model=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f10bf69cc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f10bcde7750>, root_client=<openai.OpenAI object at 0x7f10bf69dcd0>, root_async_client=<openai.AsyncOpenAI object at 0x7f10bf7da710>, model_name='chatgpt-4o-latest', model_kwargs={}, openai_api_key=SecretStr('**********'))),\n",
       " 'formatting-llm': StoredData(key='formatting-llm', config={'model_name': 'chatgpt-4o-latest', 'temperature': 0.7}, model_type='llm', model=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f10bce09490>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f10bce12050>, root_client=<openai.OpenAI object at 0x7f10bcdf8d50>, root_async_client=<openai.AsyncOpenAI object at 0x7f10bce09650>, model_name='chatgpt-4o-latest', model_kwargs={}, openai_api_key=SecretStr('**********')))}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_storage.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79336abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DialogueAugmenter(model_storage=ModelStorage(storage={'generation-llm': StoredData(key='generation-llm', config={'model_name': 'chatgpt-4o-latest', 'temperature': 0.7}, model_type='llm', model=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f10bf69cc50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f10bcde7750>, root_client=<openai.OpenAI object at 0x7f10bf69dcd0>, root_async_client=<openai.AsyncOpenAI object at 0x7f10bf7da710>, model_name='chatgpt-4o-latest', model_kwargs={}, openai_api_key=SecretStr('**********'))), 'formatting-llm': StoredData(key='formatting-llm', config={'model_name': 'chatgpt-4o-latest', 'temperature': 0.7}, model_type='llm', model=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f10bce09490>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f10bce12050>, root_client=<openai.OpenAI object at 0x7f10bcdf8d50>, root_async_client=<openai.AsyncOpenAI object at 0x7f10bce09650>, model_name='chatgpt-4o-latest', model_kwargs={}, openai_api_key=SecretStr('**********')))}), generation_llm='chatgpt-4o-latest', formatting_llm='chatgpt-4o-latest')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmenter = DialogueAugmenter(\n",
    "    model_storage=model_storage,\n",
    "    generation_llm=\"chatgpt-4o-latest\",\n",
    "    formatting_llm=\"chatgpt-4o-latest\"\n",
    ")\n",
    "augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3d1ea18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Critical error: 'chatgpt-4o-latest'\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = augmenter.invoke(\n",
    "    dialogue=D1['messages'],\n",
    "    topic=example['topic'],\n",
    "    prompt=augmentation_prompt_3_vars\n",
    ")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

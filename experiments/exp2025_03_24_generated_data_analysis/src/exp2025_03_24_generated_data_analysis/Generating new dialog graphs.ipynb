{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "damaged_topics = json.load(open('damaged_topics.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anna-\\Jupyter\\dialog2graph\\chatsky-llm-autoconfig\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:192: UserWarning: Field name \"validate\" in \"Dialogue\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dialogue2graph.datasets.complex_dialogues.generation import LoopedGraphGenerator\n",
    "from dialogue2graph import Dialogue, Graph\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = ChatOpenAI(\n",
    "    model='o1-mini',\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    ")\n",
    "val_model = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = LoopedGraphGenerator(\n",
    "    generation_model=gen_model,\n",
    "    validation_model=val_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Generating graph for topic: Recovering deleted customer support chat logs\n",
      "==================================================\n",
      "Generating Graph ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph: graph_dict={'edges': [{'source': 1, 'target': 2, 'utterances': ['I need help recovering deleted chat logs.']}, {'source': 2, 'target': 3, 'utterances': ['My email is user@example.com.']}, {'source': 2, 'target': 6, 'utterances': ['Actually, I need to update my email.']}, {'source': 6, 'target': 3, 'utterances': ['My new email is newuser@example.com.']}, {'source': 3, 'target': 4, 'utterances': ['I need logs from January 1 to January 31.']}, {'source': 3, 'target': 5, 'utterances': ['Actually, can I change the date range?']}, {'source': 5, 'target': 3, 'utterances': ['I need logs from February.']}, {'source': 3, 'target': 7, 'utterances': ['I want to cancel.']}, {'source': 4, 'target': 8, 'utterances': ['Actually, can I use the backup service instead?']}, {'source': 8, 'target': 9, 'utterances': ['Yes, I would like to use the backup service.']}, {'source': 8, 'target': 7, 'utterances': [\"No, I'd like to proceed with the original recovery.\"]}], 'nodes': [{'id': 1, 'label': 'greeting', 'is_start': True, 'utterances': ['Hello! How can I assist you today?']}, {'id': 2, 'label': 'ask_email', 'is_start': False, 'utterances': ['Sure, I can help with that. Could you please provide your account email?']}, {'id': 3, 'label': 'ask_date_range', 'is_start': False, 'utterances': ['Thank you. Could you specify the date range for the chat logs you wish to recover?']}, {'id': 4, 'label': 'processing_request', 'is_start': False, 'utterances': ['Understood. We are processing your request. You will receive an email once the logs are recovered.']}, {'id': 5, 'label': 'ask_new_date_range', 'is_start': False, 'utterances': ['Of course! What date range would you like instead?']}, {'id': 6, 'label': 'ask_new_email', 'is_start': False, 'utterances': ['Certainly! What is your new account email?']}, {'id': 7, 'label': 'early_exit', 'is_start': False, 'utterances': [\"I'm sorry to see you go. If you need further assistance, feel free to reach out anytime. Have a great day!\"]}, {'id': 8, 'label': 'alternative_method', 'is_start': False, 'utterances': ['Alternatively, you can access your chat logs through our backup service. Would you like to proceed with that option?']}, {'id': 9, 'label': 'backup_success', 'is_start': False, 'utterances': ['Your chat logs have been successfully recovered through the backup service.']}]} graph=<networkx.classes.digraph.DiGraph object at 0x000001A2FFB80790> node_mapping={}\n",
      "\n",
      "üîç Checking graph requirements...\n",
      "üîÑ Found 1 cycles in the graph:\n",
      "Cycle 1: 3 -> 5 -> 3\n",
      "‚úÖ Graph meets cycle requirements\n",
      "Sampling dialogues...\n",
      "1 repeats works!\n",
      "Sampled 5 dialogues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating and fixing transitions...\n",
      "Validating initial graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Fix attempt 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Found these [{'from_': ['Certainly! What is your new account email?'], 'user': ['My new email is newuser@example.com.'], 'to': ['Thank you. Could you specify the date range for the chat logs you wish to recover?'], 'reason': \"The assistant's first message asks for the new account email, and the user's response provides that email. However, the assistant's next message asks for a date range for the chat logs, which is out of context. The assistant should have acknowledged the new email before proceeding to the next step.\"}, {'from_': ['Thank you. Could you specify the date range for the chat logs you wish to recover?'], 'user': ['I want to cancel.'], 'to': [\"I'm sorry to see you go. If you need further assistance, feel free to reach out anytime. Have a great day!\"], 'reason': \"The assistant's question about specifying the date range for chat logs does not logically lead to the user's response of wanting to cancel. Typically, a user would respond to a request for information with that information, not with a cancellation request. Therefore, the flow is not coherent.\"}, {'from_': ['Alternatively, you can access your chat logs through our backup service. Would you like to proceed with that option?'], 'user': [\"No, I'd like to proceed with the original recovery.\"], 'to': ['Thank you. Could you specify the date range for the chat logs you wish to recover?'], 'reason': \"The assistant's first response offers an alternative method for recovering chat logs through a backup service. The user's response indicates a preference to continue with the original recovery method, which suggests that the conversation is shifting back to a previous topic. However, the assistant's next message about specifying the date range does not logically follow the user's refusal of the alternative, as it implies the conversation should proceed with the details of the original recovery without confirming the user's intent to continue with that process.\"}] invalid transitions after fix attempt\n",
      "\n",
      "üîÑ Fix attempt 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Found these [{'from_': ['Certainly! What is your new account email?'], 'user': ['My new email is newuser@example.com.'], 'to': ['Thank you. Could you specify the date range for the chat logs you wish to recover?'], 'reason': \"The assistant's first message asks for the user's new email, which logically leads to the user's response providing that email. However, the assistant's next message asks for the date range for chat logs, which does not directly follow from the user providing a new email. The flow is disrupted as the assistant should be confirming the email change first before moving on to the date range.\"}, {'from_': ['Thank you. Could you specify the date range for the chat logs you wish to recover?'], 'user': ['I want to cancel.'], 'to': [\"I'm sorry to see you go. If you need further assistance, feel free to reach out anytime. Have a great day!\"], 'reason': \"The assistant's question about specifying a date range for chat logs is not logically connected to the user's response of wanting to cancel. The user response seems abrupt and unrelated to the previous context. Therefore, the flow of the conversation is not coherent.\"}, {'from_': ['Alternatively, you can access your chat logs through our backup service. Would you like to proceed with that option?'], 'user': [\"No, I'd like to proceed with the original recovery.\"], 'to': ['Thank you. Could you specify the date range for the chat logs you wish to recover?'], 'reason': \"The user's response contradicts the assistant's previous suggestion to use the backup service, indicating a preference for the original recovery method. However, the assistant's next message asks for the date range again, which is inconsistent because the user has already provided a date range in a previous part of the conversation. This disrupts the natural flow and coherence of the dialogue.\"}] invalid transitions after fix attempt\n",
      "‚ùå Failed to generate graph for Recovering deleted customer support chat logs\n",
      "Error type: ErrorType.INVALID_GRAPH_STRUCTURE\n",
      "Error message: Found 3 invalid transitionsafter 2 fix attempts\n"
     ]
    }
   ],
   "source": [
    "generated_graph = gen.invoke(topic=damaged_topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

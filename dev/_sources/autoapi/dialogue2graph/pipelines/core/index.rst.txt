dialogue2graph.pipelines.core
=============================

.. py:module:: dialogue2graph.pipelines.core


Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/dialogue2graph/pipelines/core/algorithms/index
   /autoapi/dialogue2graph/pipelines/core/d2g_generator/index
   /autoapi/dialogue2graph/pipelines/core/dialogue/index
   /autoapi/dialogue2graph/pipelines/core/dialogue_sampling/index
   /autoapi/dialogue2graph/pipelines/core/graph/index
   /autoapi/dialogue2graph/pipelines/core/pipeline/index
   /autoapi/dialogue2graph/pipelines/core/prompt_loader/index
   /autoapi/dialogue2graph/pipelines/core/schemas/index


Classes
-------

.. autoapisummary::

   dialogue2graph.pipelines.core.RecursiveDialogueSampler
   dialogue2graph.pipelines.core.BasePipeline


Package Contents
----------------

.. py:class:: RecursiveDialogueSampler

   Bases: :py:obj:`dialogue2graph.pipelines.core.algorithms.DialogueGenerator`


   Recursive dialog sampler for the graph


   .. py:method:: invoke(graph: dialogue2graph.pipelines.core.graph.BaseGraph, cycle_ends_model: langchain_core.language_models.chat_models.BaseChatModel, upper_limit: int, sampling_max: int = 5000000) -> list[dialogue2graph.pipelines.core.dialogue.Dialogue]

      Extract all the dialogues from the graph

      :param graph: used to extract dialogues from it
      :param cycle_ends_model: LLM(BaseChatModel) to find cycling ends of the graph
      :param upper_limit: limits from above repeats_limit used in recursive get_dialogues method
      :param sampling_max: maximum number of found dialogues

      :returns: list of dialogues

      :raises ValueError: "Not all utterances present" if match_dg_triplets returns False



   .. py:method:: ainvoke(*args, **kwargs)
      :async:



   .. py:method:: evaluate(graph, upper_limit, target_dialogues, report_type=Literal['dict', 'dataframe'])
      :async:



.. py:class:: BasePipeline(/, **data: Any)

   Bases: :py:obj:`pydantic.BaseModel`


   Base class for pipelines
   .. attribute:: model_storage

      An object to manage and store models used in the pipeline.

      :type: ModelStorage

   .. attribute:: sim_model

      The key for the similarity embedder model in the model storage.

      :type: str


   .. py:attribute:: model_storage
      :type:  dialogue2graph.pipelines.model_storage.ModelStorage
      :value: None



   .. py:attribute:: sim_model
      :type:  str
      :value: None



   .. py:attribute:: name
      :type:  str
      :value: None



   .. py:attribute:: steps
      :type:  list[Union[dialogue2graph.pipelines.core.algorithms.DialogueGenerator, dialogue2graph.pipelines.core.algorithms.DialogAugmentation, dialogue2graph.pipelines.core.algorithms.GraphGenerator, dialogue2graph.pipelines.core.algorithms.GraphExtender]]
      :value: None



   .. py:method:: invoke(raw_data: dialogue2graph.pipelines.helpers.parse_data.PipelineRawDataType, enable_evals=False) -> Tuple[Any, dialogue2graph.pipelines.report.PipelineReport]

      Invoke the pipeline to process the raw data and generate a report.

      This method processes the given raw data through each step in the pipeline,
      generating both output data (result of the pipeline) and a report detailing the pipeline's execution.
      It measures execution time, performs simple graph comparisons, and optionally
      evaluates the results with more detailed comparisons.

      :param raw_data: The raw input data to be processed by the pipeline.
      :type raw_data: PipelineRawDataType
      :param enable_evals: If True, performs additional evaluations
                           and adds more detailed comparisons to the report.
      :type enable_evals: bool, optional

      :returns:

                A tuple containing the final output of the pipeline
                                            and a detailed report of the pipeline's execution.
      :rtype: Tuple[Any, PipelineReport]




{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mInstalling dependencies from lock file\u001b[39m\n",
      "\n",
      "No dependencies to install or update\n",
      "\n",
      "\u001b[39;1mInstalling\u001b[39;22m the current project: \u001b[36mdialogue2graph\u001b[39m (\u001b[39;1m0.1.1\u001b[39;22m)\u001b[1G\u001b[2K\u001b[39;1mInstalling\u001b[39;22m the current project: \u001b[36mdialogue2graph\u001b[39m (\u001b[32m0.1.1\u001b[39m)\n"
     ]
    }
   ],
   "source": [
    "! poetry install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olshevskaya/miniconda3/envs/conda_env_py311/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"validate\" in \"Dialogue\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "2025-04-30 11:04:47,142 - datasets - INFO - PyTorch version 2.6.0 available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import dotenv\n",
    "from dialogue2graph.pipelines.core.dialogue import Dialogue\n",
    "from dialogue2graph.datasets.augment_dialogues.augmentation import DialogueAugmenter\n",
    "from dialogue2graph.pipelines.model_storage import ModelStorage\n",
    "from dialogue2graph.datasets.augment_dialogues.prompts import augmentation_prompt_3_vars\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the example data to get the dialogue for augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Hi there! How can I assist you today?\n",
      "user: I want to place an order.\n",
      "assistant: Great! What product are you interested in?\n",
      "user: I’d like a t-shirt.\n",
      "assistant: What size would you like?\n",
      "user: Medium, please.\n",
      "assistant: Would you like that in red or blue?\n",
      "user: Red, please.\n",
      "assistant: Perfect! Can I have your shipping address?\n",
      "user: Sure, it’s 123 Main St.\n",
      "assistant: Thank you! Your order has been placed. Is there anything else I can help you with?\n",
      "user: Actually, can I change my order?\n",
      "assistant: Of course! What would you like to change?\n",
      "user: I want a large size.\n",
      "assistant: What size would you like?\n",
      "user: Medium, please.\n",
      "assistant: Would you like that in red or blue?\n",
      "user: Red, please.\n",
      "assistant: Perfect! Can I have your shipping address?\n",
      "user: Sure, it’s 123 Main St.\n",
      "assistant: Thank you! Your order has been placed. Is there anything else I can help you with?\n",
      "user: No, that's all. Thank you.\n",
      "assistant: Alright, feel free to reach out anytime. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "with open(\"dialogue_augmentation_data_example.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "dialogue = Dialogue(**data[0][\"dialogue\"])\n",
    "print(dialogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create `ModelStorage` instance and add choosen LLMs for dialogue generation (i.e. dialogue augmentation) and formatting LLM's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 11:09:54,533 - /cephfs/home/olshevskaya/chatsky-llm-autoconfig/dialogue2graph/pipelines/model_storage.py - INFO - Added <class 'langchain_openai.chat_models.base.ChatOpenAI'> model 'generation-llm' to storage\n",
      "2025-04-30 11:09:54,600 - /cephfs/home/olshevskaya/chatsky-llm-autoconfig/dialogue2graph/pipelines/model_storage.py - INFO - Added <class 'langchain_openai.chat_models.base.ChatOpenAI'> model 'formatting-llm' to storage\n"
     ]
    }
   ],
   "source": [
    "model_storage = ModelStorage()\n",
    "model_storage.add(\n",
    "        key=\"generation-llm\", # model to use for generation\n",
    "        config={\"model_name\": \"gpt-4o-mini-2024-07-18\", \"temperature\": 0.7},\n",
    "        model_type=ChatOpenAI,\n",
    "    )\n",
    "model_storage.add(\n",
    "        key=\"formatting-llm\", # model to use for formatting LLM's output\n",
    "        config={\"model_name\": \"gpt-3.5-turbo\", \"temperature\": 0.7},\n",
    "        model_type=ChatOpenAI,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create `DialogueAugmenter` instance and use `invoke` method to get augmented dialogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = DialogueAugmenter(\n",
    "        model_storage=model_storage,\n",
    "        generation_llm=\"generation-llm\",\n",
    "        formatting_llm=\"formatting-llm\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 11:10:20,264 - httpx - INFO - HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "result = augmenter.invoke(\n",
    "        dialogue=dialogue,\n",
    "        topic=\"Responding to DMs on Instagram/Facebook.\",\n",
    "        prompt=augmentation_prompt_3_vars,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of augmented dialogue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Hello! How may I help you today?\n",
      "user: I’d like to make a purchase.\n",
      "assistant: Awesome! Which product are you looking to buy?\n",
      "user: I would like to get a t-shirt.\n",
      "assistant: What size do you need?\n",
      "user: I need a medium size.\n",
      "assistant: Would you prefer that in red or blue?\n",
      "user: I’d like it in red, please.\n",
      "assistant: Great choice! Can I get your shipping address?\n",
      "user: It's 123 Main St.\n",
      "assistant: Thank you! Your order has been successfully placed. Is there anything else you need?\n",
      "user: Actually, I’d like to modify my order.\n",
      "assistant: Absolutely! What changes would you like to make?\n",
      "user: I want a larger size.\n",
      "assistant: What size are you looking for?\n",
      "user: Let's stick with medium, please.\n",
      "assistant: Do you want that in red or blue again?\n",
      "user: Red again, please.\n",
      "assistant: Great! Can I get your shipping address once more?\n",
      "user: It's still 123 Main St.\n",
      "assistant: Thanks! Your order has been updated. Is there anything else you would like?\n",
      "user: No, that's everything. Thanks a lot.\n",
      "assistant: Alright, don’t hesitate to reach out if you need anything else. Have a fantastic day!\n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

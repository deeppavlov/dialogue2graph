{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai  import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chatsky_llm_autoconfig.metrics.llm_metrics as llm_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsky_llm_autoconfig.graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, mode=\"r\") as file:\n",
    "        data = file.read()\n",
    "    return json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yuriypeshkichev/Projects/ipavlov/chatsky-llm-autoconfig/experiments/2024.11.14_dialogue2graph'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_json(\"../../dev_packages/chatsky_llm_autoconfig/chatsky_llm_autoconfig/autometrics/test_data/new_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatsky_llm_autoconfig.graph import BaseGraph\n",
    "from chatsky_llm_autoconfig.dialogue import Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_utterances_present(G: BaseGraph, dialogues: list[Dialogue]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if all graph elements (nodes and edges) appear in at least one dialogue.\n",
    "\n",
    "    Args:\n",
    "        G: BaseGraph object containing the dialogue graph\n",
    "        dialogues: List of Dialogue objects to check against\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all graph elements are present in at least one dialogue\n",
    "    \"\"\"\n",
    "    # Get all unique utterances from nodes and edges in the graph\n",
    "    graph_utterances = set()\n",
    "\n",
    "    # Add node utterances\n",
    "    for node_id, node_data in G.graph.nodes(data=True):\n",
    "        graph_utterances.update(node_data[\"utterances\"])\n",
    "\n",
    "    # Add edge utterances\n",
    "    for _, _, edge_data in G.graph.edges(data=True):\n",
    "        if isinstance(edge_data[\"utterances\"], list):\n",
    "            graph_utterances.update(edge_data[\"utterances\"])\n",
    "        else:\n",
    "            graph_utterances.add(edge_data[\"utterances\"])\n",
    "\n",
    "    # Collect all utterances from dialogues\n",
    "    dialogue_utterances = set()\n",
    "    for dialogue in dialogues:\n",
    "        dialogue_utterances.update(utt.text for utt in dialogue.messages)\n",
    "\n",
    "    # Check if all graph utterances are present in dialogues\n",
    "    if graph_utterances.issubset(dialogue_utterances):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        # return graph_utterances.difference(dialogue_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yuriypeshkichev/Projects/ipavlov/chatsky-llm-autoconfig/experiments/2024.11.14_dialogue2graph'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|█         | 1/10 [00:23<03:32, 23.57s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The sequence is invalid because the user's response 'Let me check again, my order number is...' logically suggests that the user is about to provide the order number again. However, the assistant's next message 'Could you provide your order number?' is redundant and does not naturally follow the user's response. The assistant should instead wait for the user to provide the order number or prompt them to do so if they haven't already.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The sequence is invalid because the user's response 'Order found' does not logically follow the assistant's message indicating that the order number could not be found. The assistant's next message assumes the order was found, which contradicts the previous statement.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 2/10 [00:48<03:13, 24.24s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|███       | 3/10 [01:11<02:46, 23.73s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|████      | 4/10 [02:09<03:43, 37.33s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 5/10 [02:34<02:44, 32.91s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 6/10 [02:54<01:53, 28.43s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|███████   | 7/10 [03:14<01:17, 25.68s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 8/10 [03:25<00:41, 20.99s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The transition is not logical because the user's response 'No' to being a client of the bank should not directly lead to the assistant suggesting creating a deposit. The logical next step would be to guide the user on how to become a client first, rather than assuming they can create a deposit without being a client.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 9/10 [03:50<00:22, 22.33s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The user's response 'Takeaway' does not logically follow the assistant's question 'Tea bags or loose tea?'. The user's response seems to be answering a different question about the order's consumption location, which is addressed in the assistant's next message 'Here or takeaway?'. Therefore, the flow is not natural or coherent.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 10/10 [04:21<00:00, 26.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             topic  are_triplets_valid  \\\n",
      "0                     Tech Support                True   \n",
      "1                    food delivery               False   \n",
      "2      Medical Appointment Booking                True   \n",
      "3                          library                True   \n",
      "4                        auto care                True   \n",
      "5             booking a hotel room                True   \n",
      "6                abstract purchase                True   \n",
      "7  chatting with a smart assistant                True   \n",
      "8          taking a loan in a bank               False   \n",
      "9                      coffee shop               False   \n",
      "\n",
      "                          are_triplets_valid_details  is_theme_valid  \\\n",
      "0                         All transitions are valid.            True   \n",
      "1  Invalid transition: The sequence is invalid be...            True   \n",
      "2                         All transitions are valid.            True   \n",
      "3                         All transitions are valid.            True   \n",
      "4                         All transitions are valid.            True   \n",
      "5                         All transitions are valid.            True   \n",
      "6                         All transitions are valid.            True   \n",
      "7                         All transitions are valid.            True   \n",
      "8  Invalid transition: The transition is not logi...            True   \n",
      "9  Invalid transition: The user's response 'Takea...            True   \n",
      "\n",
      "                              is_theme_valid_details  all_utterances_present  \n",
      "0  The dialog stays on the expected topic of tech...                    True  \n",
      "1  The dialog stays on the expected topic of food...                   False  \n",
      "2  The dialog stays on the expected topic of Medi...                    True  \n",
      "3  The dialog stays on the expected topic of the ...                    True  \n",
      "4  The dialog stays on the expected topic of auto...                    True  \n",
      "5  The dialog stays on the expected topic of book...                    True  \n",
      "6  The dialog stays on the expected topic of abst...                    True  \n",
      "7  The dialog stays on the expected topic of chat...                    True  \n",
      "8  The dialog stays on the expected topic of taki...                    True  \n",
      "9  The dialog stays on the expected topic of a co...                   False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for case in tqdm(data):\n",
    "    case_results = {\"topic\": case[\"topic\"]}\n",
    "    triplets = llm_metrics.are_triplets_valid(G=Graph(case['graph']), model=model)\n",
    "    case_results[\"are_triplets_valid\"] = triplets['value']\n",
    "    case_results['are_triplets_valid_details'] = triplets['description']\n",
    "    themes = llm_metrics.is_theme_valid(G=Graph(case['graph']), topic=case['topic'], model=model)\n",
    "    case_results['is_theme_valid'] = themes['value']\n",
    "    case_results['is_theme_valid_details'] = themes['description']\n",
    "    case_results['all_utterances_present'] = all_utterances_present(G=Graph(case['graph']), dialogues=[Dialogue(messages=x['messages']) for x in case['dialogues']])\n",
    "\n",
    "    results.append(case_results)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "df.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['is_theme_valid'] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, True, True, True, True, True, True, False]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['all_utterances_present'] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_json(\"../../dev_packages/chatsky_llm_autoconfig/chatsky_llm_autoconfig/autometrics/test_data/complex_graphs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'text': 'Good evening, how can I help?', 'participant': 'assistant'},\n",
       "  {'text': 'I want to book a duplex room', 'participant': 'user'},\n",
       "  {'text': 'How long are you going to stay?', 'participant': 'assistant'},\n",
       "  {'text': 'One night', 'participant': 'user'},\n",
       "  {'text': 'We have a vacant room. Do you need anything else?',\n",
       "   'participant': 'assistant'},\n",
       "  {'text': 'No, thanks', 'participant': 'user'},\n",
       "  {'text': 'Okay, now I need your ID card.', 'participant': 'assistant'},\n",
       "  {'text': 'Here it is', 'participant': 'user'},\n",
       "  {'text': 'Thank you. This is your key, have a good stay!',\n",
       "   'participant': 'assistant'}],\n",
       " [{'text': 'Good evening, how can I help?', 'participant': 'assistant'},\n",
       "  {'text': 'I want to book a duplex room', 'participant': 'user'},\n",
       "  {'text': 'How long are you going to stay?', 'participant': 'assistant'},\n",
       "  {'text': 'Three nights', 'participant': 'user'},\n",
       "  {'text': 'Unfortunately we do not have a vacant room for these dates, but we can offer two separate single rooms. Would this be acceptable?',\n",
       "   'participant': 'assistant'},\n",
       "  {'text': 'Okay, it will do', 'participant': 'user'},\n",
       "  {'text': 'Okay, now I need your ID card.', 'participant': 'assistant'},\n",
       "  {'text': 'Here it is', 'participant': 'user'},\n",
       "  {'text': 'Thank you. This is your key, have a good stay!',\n",
       "   'participant': 'assistant'}],\n",
       " [{'text': 'Good evening, how can I help?', 'participant': 'assistant'},\n",
       "  {'text': 'I want to book a duplex room', 'participant': 'user'},\n",
       "  {'text': 'How long are you going to stay?', 'participant': 'assistant'},\n",
       "  {'text': 'Three nights', 'participant': 'user'},\n",
       "  {'text': 'Unfortunately we do not have a vacant room for these dates, but we can offer two separate single rooms. Would this be acceptable?',\n",
       "   'participant': 'assistant'},\n",
       "  {'text': 'No, thanks, this does not suit me', 'participant': 'user'},\n",
       "  {'text': 'Can I help you with anything else?', 'participant': 'assistant'},\n",
       "  {'text': 'No, thanks', 'participant': 'user'},\n",
       "  {'text': 'Okay, goodbye!', 'participant': 'assistant'}]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case['dialogues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 1/5 [00:24<01:37, 24.44s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The transition is invalid because the user's response 'I want X' should logically lead to the assistant asking if they want to add anything to X, not directly to 'Do you want to add anything else?' which implies the user has already added something to X.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|████      | 2/5 [00:49<01:13, 24.58s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 3/5 [01:00<00:37, 18.75s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 4/5 [01:25<00:20, 20.92s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The sequence is invalid because 'Latte tea' is not a typical response to 'Which tea would you like?' as 'Latte' is usually associated with coffee. Additionally, asking about lactose-free milk after 'Latte tea' is confusing, as tea typically does not involve milk in the same way coffee does. The overall flow is not natural or coherent.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The transition is invalid because the assistant's question about needing a glass of water does not logically lead to a follow-up question about needing syrup. These are unrelated topics, and the user's affirmative response to needing water should not prompt a question about syrup. The overall flow is not coherent.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 5/5 [01:51<00:00, 22.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             topic  are_triplets_valid  \\\n",
      "0             booking a hotel room                True   \n",
      "1                abstract purchase               False   \n",
      "2  chatting with a smart assistant                True   \n",
      "3          taking a loan in a bank                True   \n",
      "4                      coffee shop               False   \n",
      "\n",
      "                          are_triplets_valid_details  is_theme_valid  \\\n",
      "0                         All transitions are valid.            True   \n",
      "1  Invalid transition: The transition is invalid ...            True   \n",
      "2                         All transitions are valid.            True   \n",
      "3                         All transitions are valid.            True   \n",
      "4  Invalid transition: The sequence is invalid be...            True   \n",
      "\n",
      "                              is_theme_valid_details  all_utterances_present  \n",
      "0  The dialog stays on the expected topic of book...                    True  \n",
      "1  The dialog stays on the expected topic of abst...                    True  \n",
      "2  The dialog stays on the expected topic of chat...                    True  \n",
      "3  The dialog stays on the expected topic of taki...                    True  \n",
      "4  The dialog stays on the expected topic of a co...                    True  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "comp_results = []\n",
    "for case in tqdm(test_data):\n",
    "    case_results = {\"topic\": case[\"topic\"]}\n",
    "    triplets = llm_metrics.are_triplets_valid(G=Graph(case['graph']), model=model)\n",
    "    case_results[\"are_triplets_valid\"] = triplets['value']\n",
    "    case_results['are_triplets_valid_details'] = triplets['description']\n",
    "    themes = llm_metrics.is_theme_valid(G=Graph(case['graph']), topic=case['topic'], model=model)\n",
    "    case_results['is_theme_valid'] = themes['value']\n",
    "    case_results['is_theme_valid_details'] = themes['description']\n",
    "    case_results['all_utterances_present'] = all_utterances_present(G=Graph(case['graph']), dialogues=[Dialogue(messages=x['messages']) for x in case['dialogues']])\n",
    "\n",
    "    comp_results.append(case_results)\n",
    "\n",
    "df = pd.DataFrame(comp_results)\n",
    "print(df)\n",
    "df.to_csv('comp_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['is_theme_valid'] for r in comp_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, True, False]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['are_triplets_valid'] for r in comp_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['all_utterances_present'] for r in comp_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response offers an alternative (two separate single rooms) after stating that there are no vacant rooms. The user's response indicates that this alternative does not suit them, which logically leads to a conclusion of the conversation rather than a request for further assistance. Therefore, the assistant's next message asking if it can help with anything else does not follow logically.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 1/5 [00:14<00:58, 14.54s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response asks what the user would like to add, and the user's response indicates they want to add Y. However, the assistant's next message asks if the user wants to order something else, which does not logically follow from the user's intent to add Y. The flow is not coherent as it skips the necessary confirmation or follow-up regarding the addition of Y.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first message asks if the user wants to add anything else, and the user responds 'No', which is a logical response. However, the assistant's next message asks if the user wants to order something else, which is not a natural follow-up to the user's 'No' response. The flow is not coherent as it suggests the user has the option to order something else after declining to add anything.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's message 'Do you want to order something else?' suggests that the user has already made an order, and the user responds 'Yes', indicating they want to order something else. However, the next message from the assistant 'What would you like to order?' implies that the user is starting a new order, which is inconsistent with the context of adding to an existing order.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|████      | 2/5 [00:40<01:03, 21.16s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 3/5 [00:49<00:30, 15.48s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's question about proceeding with the loan application does not logically lead to the user's question about becoming a client. The user seems to be asking for information unrelated to the loan application process, indicating a disconnect in the conversation flow.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 4/5 [01:04<00:15, 15.66s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's question 'Which tea would you like?' does not logically lead to the user's response 'Latte tea' because 'Latte' is a type of coffee, not tea. Therefore, the user's response is not appropriate for the context of the assistant's question.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 5/5 [01:32<00:00, 18.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             topic  are_triplets_valid  \\\n",
      "0             booking a hotel room               False   \n",
      "1                abstract purchase               False   \n",
      "2  chatting with a smart assistant                True   \n",
      "3          taking a loan in a bank               False   \n",
      "4                      coffee shop               False   \n",
      "\n",
      "                          are_triplets_valid_details  is_theme_valid  \\\n",
      "0  Invalid transition: The assistant's first resp...            True   \n",
      "1  Invalid transition: The assistant's first resp...            True   \n",
      "2                         All transitions are valid.            True   \n",
      "3  Invalid transition: The assistant's question a...            True   \n",
      "4  Invalid transition: The assistant's question '...            True   \n",
      "\n",
      "                              is_theme_valid_details  all_utterances_present  \n",
      "0  The dialog consistently revolves around the to...                    True  \n",
      "1  The dialog stays on the expected topic of abst...                    True  \n",
      "2  The dialog remains on the expected topic of ch...                    True  \n",
      "3  The dialog stays on the expected topic of taki...                    True  \n",
      "4  The dialog stays on the expected topic of a co...                    True  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "comp_mini_results = []\n",
    "for case in tqdm(test_data):\n",
    "    case_results = {\"topic\": case[\"topic\"]}\n",
    "    triplets = llm_metrics.are_triplets_valid(G=Graph(case['graph']), model=model)\n",
    "    case_results[\"are_triplets_valid\"] = triplets['value']\n",
    "    case_results['are_triplets_valid_details'] = triplets['description']\n",
    "    themes = llm_metrics.is_theme_valid(G=Graph(case['graph']), topic=case['topic'], model=model)\n",
    "    case_results['is_theme_valid'] = themes['value']\n",
    "    case_results['is_theme_valid_details'] = themes['description']\n",
    "    case_results['all_utterances_present'] = all_utterances_present(G=Graph(case['graph']), dialogues=[Dialogue(messages=x['messages']) for x in case['dialogues']])\n",
    "\n",
    "    comp_mini_results.append(case_results)\n",
    "\n",
    "df = pd.DataFrame(comp_mini_results)\n",
    "print(df)\n",
    "df.to_csv('comp_mini_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['is_theme_valid'] for r in comp_mini_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, True, False, False]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['are_triplets_valid'] for r in comp_mini_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x139406000>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x139406ba0>, root_client=<openai.OpenAI object at 0x1394041a0>, root_async_client=<openai.AsyncOpenAI object at 0x139404350>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='http://193.187.173.33:8002/api/providers/openai/v1')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|█         | 1/10 [00:17<02:37, 17.45s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response asks for the order number, which logically leads to the user's response providing the order number. However, the assistant's next message indicates a failure to find the order number, which is inconsistent with the user's response that provided a valid order number (XYZ123). This creates a logical disconnect in the flow.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response indicates that it couldn't find the order number, which should prompt the user to provide a correct order number. However, the user's response suggests they are checking again, which does not logically connect to the assistant's next message asking for the order number again.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response indicates that the order number could not be found, which should lead to the user providing a different order number or confirming the order number. The user's response 'Order found' contradicts the assistant's previous statement, making the flow incoherent.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response confirms an order was found, which should lead to a user response confirming or denying the order. However, the user's response indicates that the order is not theirs, which should logically lead to a follow-up question about verifying the order number or asking for a new order number, not back to requesting the order number again.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response indicates that the delivery address has been updated and asks for confirmation. The user's response indicates that the address is still incorrect, which should logically lead to a request for the correct address. However, the assistant's next message is a repeat of the previous request for the correct address, which disrupts the flow. Instead, the assistant should acknowledge the user's correction and then ask for the new address.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 2/10 [00:34<02:19, 17.44s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|███       | 3/10 [00:51<02:00, 17.20s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|████      | 4/10 [01:21<02:13, 22.17s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response about checking available time slots does not logically lead to the user's response asking for options. The user should be expecting a list of available time slots rather than asking for options, which implies they are looking for more information about the service itself. Therefore, the flow is not coherent.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response about the estimated cost implies that the user is close to finalizing the appointment, which does not logically lead to the user wanting to change the service type. The user's response disrupts the flow, as it suggests they are reconsidering their choice rather than proceeding with the appointment. Therefore, the transition to the assistant's next message about asking for the type of service needed is not coherent.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 5/10 [01:48<01:58, 23.78s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 6/10 [02:04<01:24, 21.13s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|███████   | 7/10 [02:23<01:01, 20.43s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 8/10 [02:35<00:35, 17.70s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's question about being a client of the bank does not logically lead to the user's response of 'No'. If the user is not a client, the assistant's next message about needing to create a deposit does not follow logically, as it assumes the user is already engaged with the bank's services. A more appropriate response would address the user's status as a non-client.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 9/10 [02:50<00:16, 16.93s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response asks for a type of tea, but the user's response 'Latte tea' is not a standard tea type; it is a coffee drink. Therefore, the user's response does not logically connect to the assistant's next message about lactose-free milk, which is relevant to coffee drinks, not tea.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's question about syrup does not logically lead to the user's response of 'No, thanks' followed by the assistant's question about 'Here or takeaway?'. The transition from asking about syrup to asking about the order's delivery method is abrupt and lacks coherence.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition: The assistant's first response about 'Tea bags or loose tea?' does not logically lead to the user's response of 'Takeaway.' The user should be responding to the type of tea they want, not indicating a preference for takeaway. Therefore, the flow is not coherent.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 10/10 [03:14<00:00, 19.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             topic  are_triplets_valid  \\\n",
      "0                     Tech Support                True   \n",
      "1                    food delivery               False   \n",
      "2      Medical Appointment Booking                True   \n",
      "3                          library                True   \n",
      "4                        auto care               False   \n",
      "5             booking a hotel room                True   \n",
      "6                abstract purchase                True   \n",
      "7  chatting with a smart assistant                True   \n",
      "8          taking a loan in a bank               False   \n",
      "9                      coffee shop               False   \n",
      "\n",
      "                          are_triplets_valid_details  is_theme_valid  \\\n",
      "0                         All transitions are valid.            True   \n",
      "1  Invalid transition: The assistant's first resp...            True   \n",
      "2                         All transitions are valid.            True   \n",
      "3                         All transitions are valid.            True   \n",
      "4  Invalid transition: The assistant's first resp...            True   \n",
      "5                         All transitions are valid.            True   \n",
      "6                         All transitions are valid.            True   \n",
      "7                         All transitions are valid.            True   \n",
      "8  Invalid transition: The assistant's question a...            True   \n",
      "9  Invalid transition: The assistant's first resp...            True   \n",
      "\n",
      "                              is_theme_valid_details  all_utterances_present  \n",
      "0  The dialog remains focused on tech support thr...                    True  \n",
      "1  The dialog consistently revolves around the to...                   False  \n",
      "2  The dialog stays on the expected topic of medi...                    True  \n",
      "3  The dialog consistently stays on the expected ...                    True  \n",
      "4  The dialog consistently stays on the expected ...                    True  \n",
      "5  The dialog stays on the expected topic of book...                    True  \n",
      "6  The dialog remains focused on the topic of mak...                    True  \n",
      "7  The dialog remains on the expected topic of ch...                    True  \n",
      "8  The dialog stays on the expected topic of taki...                    True  \n",
      "9  The dialog remains focused on the topic of a c...                   False  \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mini_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(mini_results)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmini_results.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ipavlov/chatsky-llm-autoconfig/.venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ipavlov/chatsky-llm-autoconfig/.venv/lib/python3.12/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/ipavlov/chatsky-llm-autoconfig/.venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Projects/ipavlov/chatsky-llm-autoconfig/.venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/Projects/ipavlov/chatsky-llm-autoconfig/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mini_results.csv'"
     ]
    }
   ],
   "source": [
    "mini_results = []\n",
    "for case in tqdm(data):\n",
    "    case_results = {\"topic\": case[\"topic\"]}\n",
    "    triplets = llm_metrics.are_triplets_valid(G=Graph(case['graph']), model=model)\n",
    "    case_results[\"are_triplets_valid\"] = triplets['value']\n",
    "    case_results['are_triplets_valid_details'] = triplets['description']\n",
    "    themes = llm_metrics.is_theme_valid(G=Graph(case['graph']), topic=case['topic'], model=model)\n",
    "    case_results['is_theme_valid'] = themes['value']\n",
    "    case_results['is_theme_valid_details'] = themes['description']\n",
    "    case_results['all_utterances_present'] = all_utterances_present(G=Graph(case['graph']), dialogues=[Dialogue(messages=x['messages']) for x in case['dialogues']])\n",
    "\n",
    "    mini_results.append(case_results)\n",
    "\n",
    "df = pd.DataFrame(mini_results)\n",
    "print(df)\n",
    "df.to_csv('mini_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['is_theme_valid'] for r in mini_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, True, False, True, True, True, False, False]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r['are_triplets_valid'] for r in mini_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 10%|█         | 1/10 [00:09<01:27,  9.71s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 2/10 [00:20<01:24, 10.56s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 30%|███       | 3/10 [00:33<01:20, 11.52s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|████      | 4/10 [00:49<01:18, 13.16s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 50%|█████     | 5/10 [01:01<01:04, 12.92s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 6/10 [01:07<00:41, 10.45s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 70%|███████   | 7/10 [01:13<00:26,  8.95s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 8/10 [01:23<00:18,  9.46s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 90%|█████████ | 9/10 [01:30<00:08,  8.49s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 10/10 [01:39<00:00,  9.90s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m         case_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_dialogue_valid_details\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m         dialogue_results\u001b[38;5;241m.\u001b[39mappend(case_results)\n\u001b[0;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(dialogue_results)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m     14\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdialogue_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dialogue_results = []\n",
    "for case in tqdm(data):\n",
    "\n",
    "    for dialogue in case[\"dialogues\"]:\n",
    "        case_results = {\"topic\": case[\"topic\"]}\n",
    "        res = llm_metrics.is_dialogue_valid(dialogue[\"messages\"], model=model)\n",
    "        case_results[\"is_dialogue_valid\"] = res['value']\n",
    "        case_results['is_dialogue_valid_details'] = res['description']\n",
    "\n",
    "        dialogue_results.append(case_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic': 'Tech Support',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': \"The first message from the assistant naturally starts the dialogue by offering help, which is appropriate for a tech support scenario. The final message thanks the user for contacting support and wishes them a nice day, which logically concludes the conversation after the user's issue has been resolved. The dialogue appears to be logically finished.\"},\n",
       " {'topic': 'Tech Support',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by introducing tech support and offering assistance. The final message logically connects to the previous dialogue by thanking the user after their issue was resolved, indicating a successful conclusion to the conversation.'},\n",
       " {'topic': 'Tech Support',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message from the assistant naturally starts the dialogue by offering help, which is appropriate for a tech support scenario. The final message logically connects to the previous dialogue as it thanks the user after their issue has been resolved, indicating a conclusion to the conversation. Overall, the dialogue appears to be logically finished.'},\n",
       " {'topic': 'Tech Support',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by introducing tech support and asking how they can help, which is appropriate for the context. The final message logically connects to the previous dialogue as it thanks the user after resolving their issues, indicating a conclusion to the conversation. Overall, the dialogue appears to be logically finished.'},\n",
       " {'topic': 'Tech Support',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message from the assistant naturally starts the dialogue by offering help, which is appropriate for a tech support scenario. The final message logically connects to the previous dialogue as the user confirms that their issue has been resolved, allowing the assistant to conclude the conversation politely. Overall, the dialogue appears to be logically finished.'},\n",
       " {'topic': 'Tech Support',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': \"The first message from the assistant naturally starts the dialogue by offering help, which is appropriate for a tech support scenario. The final message logically connects to the previous dialogue as it acknowledges the user's confirmation that the issue has been resolved and provides a courteous closing. The dialogue appears to be logically finished, as the user has expressed satisfaction with the assistance received.\"},\n",
       " {'topic': 'food delivery',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and introduces the food delivery service, which is a natural and appropriate way to start the dialogue. The final message thanks the user for choosing the service and wishes them a great meal, which logically concludes the conversation after confirming the order details and delivery information. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'food delivery',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and sets the context for a food delivery service, which naturally starts the dialogue. The final message thanks the user for their choice and wishes them a great meal, logically concluding the conversation after confirming the order details and delivery information. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'food delivery',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by welcoming the user and offering assistance, which is appropriate for a food delivery service. The final message logically concludes the conversation by thanking the user and wishing them a good meal, indicating that the service has been successfully provided. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'food delivery',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by welcoming the user and offering assistance, which is appropriate for a food delivery service. The final message logically connects to the previous dialogue by thanking the user after confirming the correct delivery address, indicating the conversation has reached a conclusion. Overall, the dialogue appears to be logically finished.'},\n",
       " {'topic': 'food delivery',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by welcoming the user to the food delivery service and offering assistance. The final message logically connects to the previous dialogue by thanking the user for their order and wishing them a good meal, indicating that the conversation has reached a satisfactory conclusion.'},\n",
       " {'topic': 'Medical Appointment Booking',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural way to start a dialogue in a medical appointment system. The final message confirms the appointment and wishes the user a nice day, logically concluding the conversation after the scheduling process is complete.'},\n",
       " {'topic': 'Medical Appointment Booking',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and sets the context for assistance, which is a natural start to the dialogue. The final message confirms the appointment and wishes the user a nice day, logically concluding the conversation after all necessary information has been exchanged. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'Medical Appointment Booking',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and sets the context for assistance, which is a natural start to the dialogue. The final message confirms the appointment and wishes the user a nice day, logically concluding the conversation after all necessary information has been exchanged.'},\n",
       " {'topic': 'Medical Appointment Booking',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user to the Medical Appointment System and invites them to ask for assistance, which is a natural and appropriate way to start the dialogue. The final message confirms the successful scheduling of the appointment and wishes the user a nice day, logically concluding the conversation after all necessary information has been exchanged. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'library',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural and appropriate way to start a conversation in a library setting. The final message thanks the user for their visit and wishes them a great day, which logically concludes the interaction after the user has indicated they do not need further assistance. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'library',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural and appropriate way to start a conversation in a library setting. The final message thanks the user for their interaction and wishes them a great day, which logically concludes the dialogue after the user indicates they have no further requests. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'library',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural way to start a conversation in a library setting. The final message thanks the user and wishes them a great day after completing their request, which logically concludes the interaction. The dialogue appears to be finished as the user has indicated they do not need further assistance.'},\n",
       " {'topic': 'library',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural and appropriate way to start a conversation in a library setting. The final message thanks the user for their visit and wishes them a great day, which logically concludes the interaction after the user has indicated they do not need further assistance. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'library',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user to the library and offers assistance, which is a natural and appropriate way to start the dialogue. The final message thanks the user for using the library services and wishes them a great day, which logically concludes the conversation after the user indicates they are done for the day. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'auto care',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by welcoming the user and offering assistance, which is appropriate for a service center. The final message confirms the appointment and wishes the user a great day, logically concluding the conversation after all necessary arrangements have been made. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'auto care',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural and appropriate way to start the dialogue. The final message confirms the appointment and wishes the user a great day, logically concluding the conversation after all necessary arrangements have been made. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'auto care',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural way to start a conversation at a service center. The final message confirms the appointment and wishes the user a great day, logically concluding the dialogue after the user has agreed to the appointment. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'auto care',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural and appropriate way to start the dialogue. The final message confirms the appointment and wishes the user a great day, logically concluding the conversation after all necessary arrangements have been made. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'auto care',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural and appropriate way to start the dialogue. The final message confirms the appointment and wishes the user a great day, logically concluding the conversation after all necessary arrangements have been made. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'auto care',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which naturally starts the dialogue. The final message confirms the appointment and wishes the user a great day, logically concluding the conversation after all necessary arrangements have been made. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'auto care',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural and appropriate way to start the dialogue. The final message confirms the appointment and wishes the user a great day, logically concluding the conversation after all necessary arrangements have been made. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'auto care',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user and offers assistance, which is a natural and appropriate way to start the dialogue. The final message confirms the appointment and wishes the user a great day, logically concluding the conversation after all necessary arrangements have been made. The dialogue appears to be logically finished.'},\n",
       " {'topic': 'booking a hotel room',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': \"The first message 'Good evening, how can I help?' naturally starts the dialogue by inviting the user to express their needs. The final message 'Thank you. This is your key, have a good stay!' logically concludes the conversation by providing the user with their key after completing the booking process. The dialogue appears to be logically finished.\"},\n",
       " {'topic': 'booking a hotel room',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': \"The first message 'Good evening, how can I help?' naturally starts the dialogue by inviting the user to express their needs. The final message 'Thank you. This is your key, have a good stay!' logically connects to the previous dialogue as it concludes the booking process and provides the user with their key, indicating that the conversation has reached a satisfactory end. Overall, the dialogue appears logically finished.\"},\n",
       " {'topic': 'booking a hotel room',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': \"The first message 'Good evening, how can I help?' naturally starts the dialogue by inviting the user to express their needs. The final message 'Okay, goodbye!' logically connects to the previous dialogue as the user has indicated they do not need further assistance. The dialogue appears to be logically finished.\"},\n",
       " {'topic': 'abstract purchase',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by inviting the user to make an order, which is appropriate for a service interaction. The final message logically connects to the previous dialogue by summarizing the order process and informing the user about the next steps, indicating that the conversation has reached a logical conclusion.'},\n",
       " {'topic': 'abstract purchase',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by greeting the user and inviting them to make an order. The final message logically connects to the previous dialogue by confirming the order process and informing the user about the next steps regarding their order. The dialogue appears to be logically finished as it concludes with the assistant providing information about the check and the readiness of the order.'},\n",
       " {'topic': 'chatting with a smart assistant',\n",
       "  'is_dialogue_valid': False,\n",
       "  'is_dialogue_valid_details': \"The first message 'Chatting' does not provide a clear context or purpose for the conversation, making it an awkward start. The final message 'Proceeding to weather skill' is a logical response to the user's question about the weather, but the overall dialogue lacks a coherent flow and feels unfinished.\"},\n",
       " {'topic': 'chatting with a smart assistant',\n",
       "  'is_dialogue_valid': False,\n",
       "  'is_dialogue_valid_details': \"The first message 'Chatting' does not provide a clear context or purpose for the conversation, making it an awkward start. The final message 'Proceeding to weather skill' is a logical response to the user's question about the weather, but the overall dialogue feels incomplete as it does not conclude the interaction.\"},\n",
       " {'topic': 'chatting with a smart assistant',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': \"The first message 'Chatting' naturally starts the dialogue as it indicates the assistant is ready to engage. The final message 'Proceeding to music skill' logically connects to the user's request to turn on the music, indicating the assistant is taking action based on the user's input. The dialogue appears to be logically finished as it indicates a transition to the next step.\"},\n",
       " {'topic': 'chatting with a smart assistant',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': \"The first message 'Chatting' serves as a natural opener for the dialogue, indicating the assistant is ready to engage. The final message 'Proceeding to timer skill' logically follows the user's request to set up a timer, indicating the assistant's action in response to the user's input. The dialogue appears to be logically finished as it transitions into the next step of the user's request.\"},\n",
       " {'topic': 'taking a loan in a bank',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': \"The first message 'Is there anything I can help you with?' naturally starts the dialogue by inviting the user to express their needs. The final message 'Firstly you need to create a deposit in our bank' logically follows the user's request for a loan, as it provides a necessary step for non-clients. The dialogue appears to be logically finished, as it concludes with a clear action for the user.\"},\n",
       " {'topic': 'taking a loan in a bank',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by offering assistance, which is appropriate for an assistant. The final message logically connects to the previous dialogue by providing a clear next step for the user to take in the loan process, indicating that the conversation has reached a logical conclusion.'},\n",
       " {'topic': 'taking a loan in a bank',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by offering assistance, which is appropriate for an assistant. The final message logically connects to the previous dialogue by indicating the next step in the loan process after the user expressed readiness. The dialogue appears to be logically finished as it concludes with a clear action plan.'},\n",
       " {'topic': 'taking a loan in a bank',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message naturally starts the dialogue by offering assistance, which is appropriate for an assistant. The final message logically connects to the previous dialogue, as the user indicates they have other questions instead of proceeding with the loan, suggesting the conversation is still ongoing and not yet finished.'},\n",
       " {'topic': 'coffee shop',\n",
       "  'is_dialogue_valid': False,\n",
       "  'is_dialogue_valid_details': 'The first message logically starts the dialogue by welcoming the user and asking for their order. However, the final message does not logically conclude the conversation, as it only states that green tea is unavailable without offering an alternative or closing the dialogue. This leaves the conversation feeling unfinished.'},\n",
       " {'topic': 'coffee shop',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user to the coffee shop and asks what they would like, which is a natural and appropriate way to start the conversation. The final message asks whether the user wants their order for here or takeaway, which logically follows the previous questions about their coffee order and water. The dialogue appears to be logically finished as it leads to a decision point for the user.'},\n",
       " {'topic': 'coffee shop',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user to the coffee shop and asks what they would like, which is a natural and appropriate way to start the conversation. The final message asks whether the order is for here or takeaway, which logically follows the previous questions about the coffee order. The dialogue appears to be progressing towards completion, as it is addressing all necessary aspects of the order.'},\n",
       " {'topic': 'coffee shop',\n",
       "  'is_dialogue_valid': True,\n",
       "  'is_dialogue_valid_details': 'The first message welcomes the user to the coffee shop and asks what they would like, which is a natural and appropriate way to start the conversation. The final message asks whether the user wants their order for here or takeaway, which logically follows the previous discussion about their drink order. The dialogue appears to be in a logical progression and is not abruptly finished.'},\n",
       " {'topic': 'coffee shop',\n",
       "  'is_dialogue_valid': False,\n",
       "  'is_dialogue_valid_details': \"The first message logically starts the dialogue by welcoming the user and asking for their order. However, the final message 'Here or takeaway?' is inconsistent with the user's previous response of 'Takeaway.' The dialogue does not appear to be logically finished, as the assistant's final question does not align with the user's stated preference.\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              topic  is_dialogue_valid  \\\n",
      "0                      Tech Support               True   \n",
      "1                      Tech Support               True   \n",
      "2                      Tech Support               True   \n",
      "3                      Tech Support               True   \n",
      "4                      Tech Support               True   \n",
      "5                      Tech Support               True   \n",
      "6                     food delivery               True   \n",
      "7                     food delivery               True   \n",
      "8                     food delivery               True   \n",
      "9                     food delivery               True   \n",
      "10                    food delivery               True   \n",
      "11      Medical Appointment Booking               True   \n",
      "12      Medical Appointment Booking               True   \n",
      "13      Medical Appointment Booking               True   \n",
      "14      Medical Appointment Booking               True   \n",
      "15                          library               True   \n",
      "16                          library               True   \n",
      "17                          library               True   \n",
      "18                          library               True   \n",
      "19                          library               True   \n",
      "20                        auto care               True   \n",
      "21                        auto care               True   \n",
      "22                        auto care               True   \n",
      "23                        auto care               True   \n",
      "24                        auto care               True   \n",
      "25                        auto care               True   \n",
      "26                        auto care               True   \n",
      "27                        auto care               True   \n",
      "28             booking a hotel room               True   \n",
      "29             booking a hotel room               True   \n",
      "30             booking a hotel room               True   \n",
      "31                abstract purchase               True   \n",
      "32                abstract purchase               True   \n",
      "33  chatting with a smart assistant              False   \n",
      "34  chatting with a smart assistant              False   \n",
      "35  chatting with a smart assistant               True   \n",
      "36  chatting with a smart assistant               True   \n",
      "37          taking a loan in a bank               True   \n",
      "38          taking a loan in a bank               True   \n",
      "39          taking a loan in a bank               True   \n",
      "40          taking a loan in a bank               True   \n",
      "41                      coffee shop              False   \n",
      "42                      coffee shop               True   \n",
      "43                      coffee shop               True   \n",
      "44                      coffee shop               True   \n",
      "45                      coffee shop              False   \n",
      "\n",
      "                            is_dialogue_valid_details  \n",
      "0   The first message from the assistant naturally...  \n",
      "1   The first message naturally starts the dialogu...  \n",
      "2   The first message from the assistant naturally...  \n",
      "3   The first message naturally starts the dialogu...  \n",
      "4   The first message from the assistant naturally...  \n",
      "5   The first message from the assistant naturally...  \n",
      "6   The first message welcomes the user and introd...  \n",
      "7   The first message welcomes the user and sets t...  \n",
      "8   The first message naturally starts the dialogu...  \n",
      "9   The first message naturally starts the dialogu...  \n",
      "10  The first message naturally starts the dialogu...  \n",
      "11  The first message welcomes the user and offers...  \n",
      "12  The first message welcomes the user and sets t...  \n",
      "13  The first message welcomes the user and sets t...  \n",
      "14  The first message welcomes the user to the Med...  \n",
      "15  The first message welcomes the user and offers...  \n",
      "16  The first message welcomes the user and offers...  \n",
      "17  The first message welcomes the user and offers...  \n",
      "18  The first message welcomes the user and offers...  \n",
      "19  The first message welcomes the user to the lib...  \n",
      "20  The first message naturally starts the dialogu...  \n",
      "21  The first message welcomes the user and offers...  \n",
      "22  The first message welcomes the user and offers...  \n",
      "23  The first message welcomes the user and offers...  \n",
      "24  The first message welcomes the user and offers...  \n",
      "25  The first message welcomes the user and offers...  \n",
      "26  The first message welcomes the user and offers...  \n",
      "27  The first message welcomes the user and offers...  \n",
      "28  The first message 'Good evening, how can I hel...  \n",
      "29  The first message 'Good evening, how can I hel...  \n",
      "30  The first message 'Good evening, how can I hel...  \n",
      "31  The first message naturally starts the dialogu...  \n",
      "32  The first message naturally starts the dialogu...  \n",
      "33  The first message 'Chatting' does not provide ...  \n",
      "34  The first message 'Chatting' does not provide ...  \n",
      "35  The first message 'Chatting' naturally starts ...  \n",
      "36  The first message 'Chatting' serves as a natur...  \n",
      "37  The first message 'Is there anything I can hel...  \n",
      "38  The first message naturally starts the dialogu...  \n",
      "39  The first message naturally starts the dialogu...  \n",
      "40  The first message naturally starts the dialogu...  \n",
      "41  The first message logically starts the dialogu...  \n",
      "42  The first message welcomes the user to the cof...  \n",
      "43  The first message welcomes the user to the cof...  \n",
      "44  The first message welcomes the user to the cof...  \n",
      "45  The first message logically starts the dialogu...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dialogue_results)\n",
    "print(df)\n",
    "df.to_csv('dialogue_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 20%|██        | 1/5 [00:07<00:30,  7.60s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 40%|████      | 2/5 [00:13<00:19,  6.34s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 60%|██████    | 3/5 [00:20<00:13,  6.78s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      " 80%|████████  | 4/5 [00:26<00:06,  6.68s/it]INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "100%|██████████| 5/5 [00:37<00:00,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              topic  is_dialogue_valid  \\\n",
      "0              booking a hotel room               True   \n",
      "1              booking a hotel room               True   \n",
      "2              booking a hotel room               True   \n",
      "3                 abstract purchase               True   \n",
      "4                 abstract purchase               True   \n",
      "5                 abstract purchase              False   \n",
      "6   chatting with a smart assistant              False   \n",
      "7   chatting with a smart assistant               True   \n",
      "8   chatting with a smart assistant               True   \n",
      "9   chatting with a smart assistant               True   \n",
      "10          taking a loan in a bank               True   \n",
      "11          taking a loan in a bank              False   \n",
      "12          taking a loan in a bank               True   \n",
      "13          taking a loan in a bank              False   \n",
      "14                      coffee shop              False   \n",
      "15                      coffee shop               True   \n",
      "16                      coffee shop               True   \n",
      "17                      coffee shop               True   \n",
      "18                      coffee shop               True   \n",
      "\n",
      "                            is_dialogue_valid_details  \n",
      "0   The first message 'Good evening, how can I hel...  \n",
      "1   The first message 'Good evening, how can I hel...  \n",
      "2   The first message 'Good evening, how can I hel...  \n",
      "3   The first message naturally starts the dialogu...  \n",
      "4   The first message naturally starts the dialogu...  \n",
      "5   The first message logically starts the dialogu...  \n",
      "6   The first message 'Chatting' does not provide ...  \n",
      "7   The first message 'Chatting' serves as a natur...  \n",
      "8   The first message 'Chatting' naturally starts ...  \n",
      "9   The first message 'Chatting' serves as a natur...  \n",
      "10  The first message 'Is there anything I can hel...  \n",
      "11  The first message is a logical start to the di...  \n",
      "12  The first message naturally starts the dialogu...  \n",
      "13  The first message is a natural opener for a cu...  \n",
      "14  The first message logically starts the dialogu...  \n",
      "15  The first message welcomes the user to the cof...  \n",
      "16  The first message welcomes the user to the cof...  \n",
      "17  The first message welcomes the user to the cof...  \n",
      "18  The first message welcomes the user to the cof...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = read_json(\"../../dev_packages/chatsky_llm_autoconfig/chatsky_llm_autoconfig/autometrics/test_data/complex_graphs.json\")\n",
    "dialogue_results = []\n",
    "for case in tqdm(data):\n",
    "\n",
    "    for dialogue in case[\"dialogues\"]:\n",
    "        case_results = {\"topic\": case[\"topic\"]}\n",
    "        res = llm_metrics.is_dialogue_valid(dialogue[\"messages\"], model=model)\n",
    "        case_results[\"is_dialogue_valid\"] = res['value']\n",
    "        case_results['is_dialogue_valid_details'] = res['description']\n",
    "\n",
    "        dialogue_results.append(case_results)\n",
    "df = pd.DataFrame(dialogue_results)\n",
    "print(df)\n",
    "df.to_csv('dialogue_complex_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

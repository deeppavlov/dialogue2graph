extending_llm:
  config:
    model_name: chatgpt-4o-latest
    temperature: 0
  model_type: <class 'langchain_openai.chat_models.base.ChatOpenAI'>
filling_llm:
  config:
    model_name: o3-mini
    temperature: 1
  model_type: <class 'langchain_openai.chat_models.base.ChatOpenAI'>
formatting_llm:
  config:
    model_name: gpt-4o-mini
    temperature: 0
  model_type: <class 'langchain_openai.chat_models.base.ChatOpenAI'>
grouping_llm:
  config:
    model_name: chatgpt-4o-latest
    temperature: 0
  model_type: <class 'langchain_openai.chat_models.base.ChatOpenAI'>
sim_model:
  config:
    model_kwargs:
      device: cuda:0
    model_name: BAAI/bge-m3
  model_type: <class 'langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings'>
